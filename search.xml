<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>python pep8 代码规范</title>
    <url>/2022/01/13/python%20-%20python%20pep8%20%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/</url>
    <content><![CDATA[<p>写出优雅、规范的代码是程序员的基础能力，这篇文章一起学习一下 python pep8 规范。</p>
<span id="more"></span>

<h1 id="1-代码编排"><a href="#1-代码编排" class="headerlink" title="1. 代码编排"></a>1. 代码编排</h1><ul>
<li>缩进。四个空格，不要使用tab。</li>
<li>每行最大长度79，换行使用圆括号。</li>
<li>空行。top-level函数之间空两行；类和函数定义之间空两行；类中的方法定义之间空一行；逻辑无关的段落空一行；其他地方尽量不要再空行。</li>
</ul>
<h1 id="2-import"><a href="#2-import" class="headerlink" title="2. import"></a>2. import</h1><ul>
<li>import按标准、三方和自己编写顺序依次排放，之间空一行。</li>
<li>不要一句import多个库。</li>
</ul>
<h1 id="3-空格"><a href="#3-空格" class="headerlink" title="3. 空格"></a>3. 空格</h1><ul>
<li>尽量避免不必要的空格</li>
<li>各种右括号前不加空格。</li>
<li>各种左括号后不加空格。</li>
<li>逗号、冒号、分号前不加空格。</li>
<li>操作符左右各加一个空格，不要为了对齐增加空格。</li>
<li>函数默认参数使用的赋值符左右省略空格。</li>
<li>不要将多句语句写在同一行。</li>
<li>if/for/while语句中，即使执行语句只有一句，也必须另起一行。</li>
</ul>
<h1 id="4-注释"><a href="#4-注释" class="headerlink" title="4. 注释"></a>4. 注释</h1><ul>
<li>错误的注释不如没有注释。代码发生改变后要立马修改对应注释。</li>
<li>注释必须采用英文，最好是完整的句子，行首字母大写。</li>
<li><code>#</code>后需要加空格。</li>
<li>尽量让代码、命名自解释。优秀代码 &gt; 烂代码 + 好注释。</li>
<li>避免无谓注释。</li>
</ul>
<h1 id="5-命名规范"><a href="#5-命名规范" class="headerlink" title="5. 命名规范"></a>5. 命名规范</h1><ul>
<li>模块命名尽量短小，使用全部小写的方式，可以使用下划线。</li>
<li>包命名尽量短小，使用全部小写的方式，不可以使用下划线。</li>
<li>类的命名使用CapWords的方式，模块内部使用的类采用_CapWords的方式。</li>
<li>异常命名使用CapWords+Error后缀的方式。</li>
<li>全局变量尽量只在模块内有效，类似C语言中的static。实现方法有两种，一是__all__机制;二是前缀一个下划线。</li>
<li>函数命名使用全部小写的方式，可以使用下划线。</li>
<li>常量命名使用全部大写的方式，可以使用下划线。</li>
<li>类的属性（方法和变量）命名使用全部小写的方式，可以使用下划线。</li>
<li>类的属性若与关键字名字冲突，后缀一下划线，尽量不要使用缩略等其他方式。</li>
<li>类的方法第一个参数必须是self。</li>
<li><a href="https://blog.csdn.net/yanyuxiangtoday/article/details/119767148">点我看《编写可读代码的艺术》。</a></li>
</ul>
<p>Python之父Guido推荐的规范：<br><img src="https://img-blog.csdnimg.cn/ca6a5e46d9a94783bd5ff5a68470d1ef.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6ZuB5a6HdXA=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<h1 id="6-编码建议"><a href="#6-编码建议" class="headerlink" title="6. 编码建议"></a>6. 编码建议</h1><ul>
<li>尽可能使用‘is’ ‘is not’取代‘==’，比如if x is not None 要优于if x。</li>
<li>使用基于类的异常，每个模块或包都有自己的异常类，此异常类继承自Exception。</li>
<li>异常中不要使用裸露的except，except后跟具体的exceptions。</li>
<li>异常中try的代码尽可能少</li>
<li>使用startswith() and endswith()代替切片进行序列前缀或后缀的检查</li>
<li>使用isinstance()比较对象的类型。</li>
<li>判断序列空或不空，直接 if seq，不要用 if len(seq)这种方式。</li>
<li>字符串不要以空格收尾。</li>
<li>如果一个类不继承自其它类, 就显式的从object继承. 如<code>class SampleClass(object)...</code></li>
</ul>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>coding</tag>
      </tags>
  </entry>
  <entry>
    <title>分发自己的python包</title>
    <url>/2022/01/13/python%20-%20%E5%88%86%E5%8F%91%E8%87%AA%E5%B7%B1%E7%9A%84python%E5%8C%85/</url>
    <content><![CDATA[<h1 id="0-前言"><a href="#0-前言" class="headerlink" title="0. 前言"></a>0. 前言</h1><p>哪一个程序员不想有一个自己的包呢？<br>在项目开发工作中，会用到大量工具。虽然可以把这些工具模块化之后再不同项目中复制粘贴，但是既繁琐又不够酷。但是如果可以分发自己的包？够酷！</p>
<span id="more"></span>
<h1 id="1-创建自己的项目"><a href="#1-创建自己的项目" class="headerlink" title="1. 创建自己的项目"></a>1. 创建自己的项目</h1><ul>
<li>这个项目的目录结构<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">|--project </span><br><span class="line">	| --example_pkg</span><br><span class="line">			|--_init__.py</span><br><span class="line">			|--hello.py</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="2-编写包的功能"><a href="#2-编写包的功能" class="headerlink" title="2. 编写包的功能"></a>2. 编写包的功能</h1><ul>
<li>就和日常写代码一样，把自己经常需要用的函数模块化之后封装好即可。</li>
</ul>
<h1 id="3-创建配置文件"><a href="#3-创建配置文件" class="headerlink" title="3. 创建配置文件"></a>3. 创建配置文件</h1><ul>
<li>按照以下格式和目录层级增加三个文件，内容稍后会介绍。<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">|--project</span><br><span class="line">	|--example_pkg</span><br><span class="line">		|--__init__.py</span><br><span class="line">		|--hello.py</span><br><span class="line">	|--setup.py</span><br><span class="line">	|--LICENSE</span><br><span class="line">	|--README.md</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="3-1-setup-py"><a href="#3-1-setup-py" class="headerlink" title="3.1 setup.py"></a>3.1 setup.py</h2><ul>
<li>这个是setuptools的构建脚本。告诉setuptools一些必须的信息。可以直接参照我的写。<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import setuptools</span><br><span class="line"></span><br><span class="line">with open(&quot;README.md&quot;, &quot;r&quot;) as fh:</span><br><span class="line">    long_description = fh.read()</span><br><span class="line"></span><br><span class="line">setuptools.setup(</span><br><span class="line">    name=&quot;example_pkg&quot;,</span><br><span class="line">    version=&quot;0.0.1&quot;,</span><br><span class="line">    author=&quot;your name&quot;,</span><br><span class="line">    author_email=&quot;your_name@example.com&quot;,</span><br><span class="line">    description=&quot;Briefly describe your package&quot;,</span><br><span class="line">    long_description=long_description,</span><br><span class="line">    long_description_content_type=&quot;text/markdown&quot;,</span><br><span class="line">    url=&quot;https://github.com/your_id/your_project&quot;,</span><br><span class="line">    packages=setuptools.find_packages(),</span><br><span class="line">    classifiers=[</span><br><span class="line">        &quot;Programming Language :: Python :: 3&quot;,</span><br><span class="line">        &quot;License :: OSI Approved :: MIT License&quot;,</span><br><span class="line">        &quot;Operating System :: OS Independent&quot;,</span><br><span class="line">    ],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="3-2-README-md"><a href="#3-2-README-md" class="headerlink" title="3.2 README.md"></a>3.2 README.md</h2></li>
<li>在这里写一些对包的详细说明。<h2 id="3-3-LICENSE"><a href="#3-3-LICENSE" class="headerlink" title="3.3 LICENSE"></a>3.3 LICENSE</h2></li>
<li>许可信息，通常我们采用MIT许可，将以下内容复制到LICENSE中。<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Copyright (c) 2018 The Python Packaging Authority</span><br><span class="line"></span><br><span class="line">Permission is hereby granted, free of charge, to any person obtaining a copy</span><br><span class="line">of this software and associated documentation files (the &quot;Software&quot;), to deal</span><br><span class="line">in the Software without restriction, including without limitation the rights</span><br><span class="line">to use, copy, modify, merge, publish, distribute, sublicense, and/or sell</span><br><span class="line">copies of the Software, and to permit persons to whom the Software is</span><br><span class="line">furnished to do so, subject to the following conditions:</span><br><span class="line"></span><br><span class="line">The above copyright notice and this permission notice shall be included in all</span><br><span class="line">copies or substantial portions of the Software.</span><br><span class="line"></span><br><span class="line">THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span><br><span class="line">IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span><br><span class="line">FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE</span><br><span class="line">AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER</span><br><span class="line">LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,</span><br><span class="line">OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE</span><br><span class="line">SOFTWARE.</span><br></pre></td></tr></table></figure>
<h1 id="4-生成分发文档"><a href="#4-生成分发文档" class="headerlink" title="4. 生成分发文档"></a>4. 生成分发文档</h1></li>
<li>安装setuptools、wheel、twine包<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ pip3 install --upgrade setuptools wheel twine</span><br></pre></td></tr></table></figure></li>
<li>在项目根目录下运行<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ python3 setup.py sdist bdist_wheel</span><br></pre></td></tr></table></figure></li>
<li>该命令会在项目下生成build文件夹和dist文件夹，内含构建信息<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">|--project</span><br><span class="line">	|--build</span><br><span class="line">		|--xxx</span><br><span class="line">	|--dist</span><br><span class="line">		|--example_pkg-0.0.1-py3-none-any.whl</span><br><span class="line">		|--example_pkg-0.0.1.tar.gz</span><br><span class="line">	|--example_pkg</span><br><span class="line">		|--__init__.py</span><br><span class="line">		|--hello.py</span><br><span class="line">	|--setup.py</span><br><span class="line">	|--LICENSE</span><br><span class="line">	|--README.md</span><br></pre></td></tr></table></figure>
<h1 id="5-上传PyPI并测试"><a href="#5-上传PyPI并测试" class="headerlink" title="5. 上传PyPI并测试"></a>5. 上传PyPI并测试</h1></li>
<li>在<a href="https://test.pypi.org/account/register/">Test PyPI</a>和<a href="https://pypi.org/account/register/">PyPI</a>上个注册一个账户（可以相同），Test PyPI是用于测试的，PyPI是正式发布的。</li>
<li>使用twine upload命令上传dist目录下的存档<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ python3 -m twine upload --repository-url https://test.pypi.org/legacy/ dist/*</span><br></pre></td></tr></table></figure></li>
<li>安装当前库的测试版并测试<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ pip3 install --index-url https://test.pypi.org/simple --no-deps example_pkg</span><br><span class="line">$ python3</span><br><span class="line">&gt;&gt;&gt; import example_pkg</span><br><span class="line">&gt;&gt;&gt; example_pkg.your_function</span><br></pre></td></tr></table></figure>
<h1 id="6-正式发布"><a href="#6-正式发布" class="headerlink" title="6. 正式发布"></a>6. 正式发布</h1></li>
<li>测试完每个函数没问题就可以正式发布了，执行命令：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ python3 -m twine upload dist/*</span><br></pre></td></tr></table></figure></li>
<li>然后就可以愉快的安装你的库了<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ pip3 install example_pkg</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="ps"><a href="#ps" class="headerlink" title="ps"></a>ps</h1><p>可以参考我的<a href="https://github.com/yanyuxiangToday/yyx_tools">github repo</a>，有时候会将在不同的项目中大量用到的代码都放到这个工具包中，可以大幅降低自己的代码量。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>【python基础 - 02】__len__</title>
    <url>/2022/01/13/%E3%80%90python%E5%9F%BA%E7%A1%80%20-%2002%E3%80%91__len__%20/</url>
    <content><![CDATA[<p><code>__len__</code>方法是一种常见的方法，顾名思义，主要用于判断某个类的长度。</p>
<span id="more"></span>

<p>定义<code>Test</code>类如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.num_list = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.num_list)</span><br></pre></td></tr></table></figure>

<p>执行</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = Test()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面两行等价</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(x.num_list))</span><br><span class="line"><span class="built_in">print</span>(x.__len__())</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">3</span><br><span class="line">3</span><br></pre></td></tr></table></figure>

<p>由此可以看出<code>__len__</code>方法主要用于判断类中某属性的长度，只是直接调用<code>len(x)</code>时预设了输出某种属性的长度。</p>
<p>如果将代码改为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.num_list = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(x))</span><br></pre></td></tr></table></figure>
<p>则会输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;xxx&quot;, line 9, in &lt;module&gt;</span><br><span class="line">    print(x.__len__())</span><br><span class="line">AttributeError: &#x27;Test&#x27; object has no attribute &#x27;__len__&#x27;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>【python基础 - 03】__getitem__</title>
    <url>/2022/01/13/%E3%80%90python%E5%9F%BA%E7%A1%80%20-%2003%E3%80%91__getitem__/</url>
    <content><![CDATA[<p><code>__getitem__</code>方法是一种常见的方法，常用于获取类中的某些信息。</p>
<span id="more"></span>

<p>以<code>dict</code>的情况举例，定义<code>Test</code>类如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.<span class="built_in">dict</span> = <span class="built_in">dict</span>(</span><br><span class="line">            m_key=<span class="string">&#x27;m_value&#x27;</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, key</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.<span class="built_in">dict</span>[key]</span><br></pre></td></tr></table></figure>

<p>执行</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = Test()</span><br><span class="line"><span class="built_in">print</span>(x[<span class="string">&#x27;m_key&#x27;</span>])</span><br></pre></td></tr></table></figure>

<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">m_value</span><br></pre></td></tr></table></figure>

<p>由此可以看出<code>__getitem__</code>方法主要用于获取类中的某些信息，当然你也可以定义其他数据结构，尝试写自己的<code>__getitem__</code>，通常在项目中的config文件中会使用。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>【python基础 - 04】__getattr__</title>
    <url>/2022/01/13/%E3%80%90python%E5%9F%BA%E7%A1%80%20-%2004%E3%80%91__getattr__/</url>
    <content><![CDATA[<p><code>__getattr__</code>方法常用于以属性的方式调用类中的属性或方法，如<code>MyClass.my_func()</code>.</p>
<span id="more"></span>

<p>定义<code>Test</code>类如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_my_default</span>(<span class="params">self, *args</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;func input <span class="subst">&#123;args&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getattr__</span>(<span class="params">self, key</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;key&#125;</span> not defined in Test&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> self._my_default</span><br></pre></td></tr></table></figure>

<p>执行</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = Test()</span><br><span class="line">x.test_func(<span class="string">&#x27;test getattr&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">test_func not defined in Test</span><br><span class="line">func input (&#x27;test getattr&#x27;,)</span><br></pre></td></tr></table></figure>

<p>由此可以看出采用<code>.</code>的形式去调用属性、方法时就是在调用<code>__getattr__</code>，我们还可以使用该特性实现以属性的方式去调用<code>dict</code>中的元素，示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dict2Attr</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, m_dict</span>):</span></span><br><span class="line">        self.m_dict = m_dict</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getattr__</span>(<span class="params">self, key</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.m_dict[key]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">m_dict = <span class="built_in">dict</span>(</span><br><span class="line">    item1=<span class="string">&#x27;value1&#x27;</span>,</span><br><span class="line">    item2=<span class="string">&#x27;value2&#x27;</span>,</span><br><span class="line">)</span><br><span class="line">m_attr_dict = Dict2Attr(m_dict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下每两行都是等价的</span></span><br><span class="line"><span class="built_in">print</span>(m_dict[<span class="string">&#x27;item1&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(m_attr_dict.item1)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m_dict[<span class="string">&#x27;item2&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(m_attr_dict.item2)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(m_dict[<span class="string">&#x27;item3&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(m_attr_dict.item3)  <span class="comment"># 执行结果同上</span></span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">value1</span><br><span class="line">value1</span><br><span class="line">value2</span><br><span class="line">value2</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;xxx&quot;, line 22, in &lt;module&gt;</span><br><span class="line">    print(m_dict[&#x27;item3&#x27;])</span><br><span class="line">KeyError: &#x27;item3&#x27;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>【python基础 - 05】__all__</title>
    <url>/2022/01/13/%E3%80%90python%E5%9F%BA%E7%A1%80%20-%2005%E3%80%91__all__/</url>
    <content><![CDATA[<p><code>__all__</code>通常用于项目中的引用保护。</p>
<span id="more"></span>

<p>定义<code>aa.py</code>文件如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">a1</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;a1 from aa.py&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">a2</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;a2 from aa.py&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>定义<code>bb.py</code>文件如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from aa import *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a1()</span><br><span class="line">a2()</span><br></pre></td></tr></table></figure>

<p>执行<code>bb.py</code>，得到输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a1 from aa.py</span><br><span class="line">a2 from aa.py</span><br></pre></td></tr></table></figure>

<p>将<code>aa.py</code>修改为</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">__all__ = [<span class="string">&#x27;a1&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">a1</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;a1 from aa.py&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">a2</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;a2 from aa.py&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>此时执行<code>bb.py</code>，得到输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a1 from aa.py</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;bb.py&quot;, line 4, in &lt;module&gt;</span><br><span class="line">    a2()</span><br><span class="line">NameError: name &#x27;a2&#x27; is not defined</span><br></pre></td></tr></table></figure>

<p>将<code>bb.py</code>修改为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> aa <span class="keyword">import</span> a1, a2  <span class="comment"># IDE一般会提示 &quot;&#x27;a2&#x27; is not declared in __all__&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a1()</span><br><span class="line">a2()</span><br></pre></td></tr></table></figure>

<p>执行<code>bb.py</code>，得到输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a1 from aa.py</span><br><span class="line">a2 from aa.py</span><br></pre></td></tr></table></figure>

<p>由此可见<code>__all__</code>可以作为一种<code>import</code>的保护机制，另外<code>from ... import ...</code>的形式不会受<code>__all__</code>的影响。不过在项目中最好还是采用<code>from module import func1, func2</code>的形式，这样会更加规范，可读性也会更好。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>【python基础 - 01】__call__</title>
    <url>/2022/01/13/%E3%80%90python%E5%9F%BA%E7%A1%80%20-%2001%E3%80%91__call__/</url>
    <content><![CDATA[<p><code>__call__</code>方法是一种常见的方法，顾名思义，主要用于调用某个类。</p>
<span id="more"></span>

<p>定义<code>Test</code>类如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, <span class="built_in">any</span>=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">any</span>)</span><br></pre></td></tr></table></figure>

<p>执行</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = Test()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面三行等价</span></span><br><span class="line">Test()()</span><br><span class="line">x.__call__()</span><br><span class="line">x()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面三行等价</span></span><br><span class="line">Test()(<span class="string">&#x27;hello&#x27;</span>)</span><br><span class="line">x.__call__(<span class="string">&#x27;hello&#x27;</span>)</span><br><span class="line">x(<span class="string">&#x27;hello&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">None</span><br><span class="line">None</span><br><span class="line">None</span><br><span class="line"></span><br><span class="line">hello</span><br><span class="line">hello</span><br><span class="line">hello</span><br></pre></td></tr></table></figure>

<p>由此可以看出<code>__call__</code>方法主要用于调用某个类，通常在深度学习框架中，如keras，pytorch中常能见到该写法，如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y = tf.keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)(x)</span><br></pre></td></tr></table></figure>
<p>等价于</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tf.keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>).__call__(x)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 02】交叉熵</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2002%E3%80%91%E4%BA%A4%E5%8F%89%E7%86%B5/</url>
    <content><![CDATA[<p>交叉熵通常用于各种分类任务中，这篇文章会对交叉熵做一个简单介绍。</p>
<span id="more"></span>
<h1 id="为什么使用交叉熵而不是MSE等损失函数作为分类loss"><a href="#为什么使用交叉熵而不是MSE等损失函数作为分类loss" class="headerlink" title="为什么使用交叉熵而不是MSE等损失函数作为分类loss"></a>为什么使用交叉熵而不是MSE等损失函数作为分类loss</h1><ul>
<li>最主要原因是交叉熵的梯度较为友好。如果用MSE计算loss，则输出的loss曲线是波动的，有很多局部的极值点，任务会演变成非凸优化问题，简单来说就是模型参数很容易进入到一个局部极值点出不来。使用交叉熵作为损失函数可以保证任务依然是凸优化问题，在求导梯度时候有很好的收敛特性。<h1 id="什么是熵"><a href="#什么是熵" class="headerlink" title="什么是熵"></a>什么是熵</h1></li>
<li>想要理解交叉熵，就需要知道什么是熵。熵可以直观的理解为信息量。“明天太阳会从东边升起”，这句话信息量就比较小，是一个正确的废话。“明天中国会成为世界第一大经济体”，这句话信息量就多一些，不管是真的假的，信息量大的东西更会引起我们的关注。</li>
<li>数学公式。其中P(x)表示事件x可能发生的概率，E(x)就是熵，熵的另一个名字叫做自信息量。想要进一步理解熵，就需要知道KL散度。<br><img src="https://img-blog.csdnimg.cn/0e102161473141539068750e758d6695.png" alt="在这里插入图片描述"><h1 id="KL散度"><a href="#KL散度" class="headerlink" title="KL散度"></a>KL散度</h1></li>
<li>KL散度，又称为KL距离，还有一个名字叫做相对熵，是一种量化两种概率分布之间差异的方式，可以理解为两个概率分布之间信息量的差别。</li>
<li>数学公式（注意下式P的下标）。<br><img src="https://img-blog.csdnimg.cn/a4686983b36943a2ad3187b4a94b7043.png" alt="在这里插入图片描述"></li>
<li>相对熵是不对称的，也就是说A到B的相对熵（或者说KL距离）不等于B到A的相对熵（或者说KL距离），由于这种数学特性，相对熵这种度量两个概率分布之间差异的方式刚好可以适用于多分类任务。那么相对熵这么符合多分类任务需求，为什么采用交叉熵而不是相对熵呢？<h1 id="为什么采用交叉熵而不是相对熵"><a href="#为什么采用交叉熵而不是相对熵" class="headerlink" title="为什么采用交叉熵而不是相对熵"></a>为什么采用交叉熵而不是相对熵</h1></li>
<li>这个问题的答案很简单，我们看交叉熵和相对熵的关系：<ul>
<li>A和B的交叉熵 = A和B的相对熵 - A的信息熵</li>
</ul>
</li>
<li>因此，为了简化计算，通常我们直接采用交叉熵作为损失函数，最终数学公式为（注意P的下标）<br><img src="https://img-blog.csdnimg.cn/18a5caa16da34f1abe9003dbaefd512e.png" alt="在这里插入图片描述"></li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 04】过拟合和欠拟合的概念及解决方案</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2004%E3%80%91%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88%E7%9A%84%E6%A6%82%E5%BF%B5%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
    <content><![CDATA[<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><ul>
<li>过拟合就是随着模型的训练，模型在训练集上的表现越来越好，但是在验证集上的表现却越来越差，也就是说对训练集的拟合程度过高，导致模型的泛化能力降低。<span id="more"></span></li>
<li>欠拟合就是模型在训练集上也无法达到满意的精度。<h1 id="过拟合的解决方案"><a href="#过拟合的解决方案" class="headerlink" title="过拟合的解决方案"></a>过拟合的解决方案</h1>过拟合通常是由于训练数据过少、模型复杂度过大等问题导致的，因此相应的解决方案也是从这两个角度考虑。</li>
<li>使用更多的数据进行训练，并且数据集尽量均匀，做一些数据增强。</li>
<li>降低模型复杂度。并不是说模型越复杂越好，如果模型过于复杂，而训练集又较少，那么参数就很容易拟合到一个过于适配训练集的参数空间中，自然就会导致过拟合的出现。</li>
<li>Early Stop，简单来说就是减少迭代次数。随着训练次数的增加，模型对训练数据的拟合程度也会随之增高，所以也可以通过减少训练时间的方法避免过拟合，提高模型泛化能力。</li>
<li>L1、L2正则化方法，限制模型权重。</li>
<li>在数据中增加一些噪声，从而通过影响损失函数的优化方向避免过拟合。</li>
<li>Dropout，目的也是降低模型的复杂度。</li>
<li>ResNet。是的，ResNet也可以解决过拟合问题，因为ResNet的跳线结构可以让部分参数权重归零，进而达到类似于Dropout的效果。<h1 id="欠拟合的解决方案"><a href="#欠拟合的解决方案" class="headerlink" title="欠拟合的解决方案"></a>欠拟合的解决方案</h1>欠拟合通常是由于模型表征能力不足、数据量过大导致的，刚好和过拟合相反。</li>
<li>使用更复杂的模型。</li>
<li>增加迭代次数。</li>
<li>减少数据中的噪声。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 05】采用奇数卷积核的原因</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2005%E3%80%91%E9%87%87%E7%94%A8%E5%A5%87%E6%95%B0%E5%8D%B7%E7%A7%AF%E6%A0%B8%E7%9A%84%E5%8E%9F%E5%9B%A0/</url>
    <content><![CDATA[<p>在计算机视觉任务中，常见的卷积核选择都是3x3、5x5、7x7的，为什么很少见到偶数的卷积核呢？</p>
<span id="more"></span>
<ul>
<li>其主要原因是为了保护位置信息，使用奇数的卷积核，保证了中心点刚好在中间，避免了位置信息发生偏移。在需要使用位置信息的任务，如目标检测、目标识别、三维重建、图像重建等任务中非常有价值。</li>
<li>另一个就是因为padding时候能够保证左右对称，实际上也是为了位置信息。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 03】梯度消失和梯度爆炸的概念及解决方案</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2003%E3%80%91%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E5%92%8C%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E7%9A%84%E6%A6%82%E5%BF%B5%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
    <content><![CDATA[<p>梯度消失和梯度爆炸是人工智能领域出现的高频词汇，这篇文章对其进行简要介绍。</p>
<span id="more"></span>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><ul>
<li>梯度消失就是指在网络反向传播过程中由于链式求导法则不断的累积，如果每一层的梯度都小于1，由于累乘效应，出现了某些参数的梯度非常小的现象。在使用这些梯度更新梯度的时候参数值基本没有发生变化，因此就出现了网络训练停滞、模型无法继续优化的问题。</li>
<li>梯度爆炸与之刚好相反，在网络反向传播过程中由于链式求导法则的累乘效应，在每一层梯度都大于1的时候，就可能会出现某些参数的梯度非常大。在使用这些梯度更新参数的时候就会导致参数变化过大，就会出现损失函数震荡的现象。<h1 id="梯度消失和梯度爆炸的解决方案"><a href="#梯度消失和梯度爆炸的解决方案" class="headerlink" title="梯度消失和梯度爆炸的解决方案"></a>梯度消失和梯度爆炸的解决方案</h1></li>
<li>预训练和fine-tuning<ul>
<li>就是将一些在公开训练集上训练好的模型参数加载到自己对应的模型中，这样损失函数通常就能稳定的优化。</li>
</ul>
</li>
<li>梯度裁剪<ul>
<li>梯度裁剪是一个针对梯度爆炸的解决方案，也就是说将梯度限制在某个阈值范围内，如果梯度超过的这个阈值，那么就将其设置为这个阈值。</li>
</ul>
</li>
<li>正则化<ul>
<li>正则化也是一种限制梯度爆炸的解决方案，同时也有限制过拟合的作用。</li>
</ul>
</li>
<li>使用relu、leakrelu、elu等激活函数<ul>
<li>梯度消失通常是因为损失函数选择sigmoid导致的，而relu激活函数在正数部分梯度是恒等于1的，由于1不会累积加权的特性，自然就可以避免梯度消失或梯度爆炸现象。但是relu同样有缺点，作为分段函数，relu在负数部分恒为0，导致一些神经元无法被激活。而leakyrelu、elu就可以避免这个问题。</li>
</ul>
</li>
<li>BN（batch normalization）<ul>
<li>BN可以加速网络收敛提升训练的稳定性，它把每一层神经网络的任意神经元输入值的分布规范为正态分布，如果采用sigmoid激活函数，那么就可以使得激活函数的输入落在梯度较大的区域，因此就能一定程度解决梯度消失的问题。</li>
</ul>
</li>
<li>使用类似ResNet的跳线结构<ul>
<li>由于离输出近的层学习效果好，而由于链式求导法则的影响可能会导致梯度消失或者梯度爆炸，因此可以模仿ResNet在网络的中间增加跳线结构，这样对应层求导梯度时候由于跳线的连接可以增加一个让梯度无损传播的通路，从而避免梯度消失或者梯度爆炸。</li>
</ul>
</li>
<li>LSTM等结构<ul>
<li>在NLP领域中，LSTM有时也会被用于对抗梯度现象，这是由于其具有复杂的门结构来控制梯度更新。</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 01】L1和L2损失函数的区别</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2001%E3%80%91L1%E5%92%8CL2%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p>机器学习、深度学习任务中经常提到L1和L2损失的概念，在这里简单介绍一下它们的基础概念以及区别。</p>
<span id="more"></span>
<h1 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h1><ul>
<li>L1损失函数又称为MAE(mean abs error)，即平均绝对误差，也就是预测值和真实值之间差值的绝对值。</li>
<li>L2损失函数又称为MSE(mean square error)，即平均平方误差，也就是预测值和真实值之间差值的平方。<h1 id="相同点"><a href="#相同点" class="headerlink" title="相同点"></a>相同点</h1></li>
<li>因为计算的方式类似，只有一个平方的差异，因此使用的场合都很相近，通常用于回归任务中。<h1 id="差异"><a href="#差异" class="headerlink" title="差异"></a>差异</h1></li>
<li>L2没有L1鲁棒，直观来说，L2会将误差平方，如果误差大于1，则误差会被放大很多，因此模型会对异常样本更敏感，这样会牺牲许多正常的样本。当训练集中含有更多异常值的时候，L1会更有效。</li>
<li>如果是图像重建任务，如超分辨率、深度估计、视频插帧等，L2会更加有效，这是由任务特性决定的，图像重建任务中通常预测值和真实值之间的差异不大，因此需要用L2损失来放大差异，进而指导模型的优化。</li>
<li>L1的问题在于它的梯度在极值点会发生跃变，并且很小的差异也会带来很大的梯度，不利于学习，因此在使用时通常会设定学习率衰减策略。而L2作为损失函数的时候本身由于其函数的特性，自身就会对梯度进行缩放，因此有的任务在使用L2时甚至不会调整学习率，不过随着现在的行业认知，学习率衰减策略在很多场景中依然是获得更优模型的手段。<h1 id="变体"><a href="#变体" class="headerlink" title="变体"></a>变体</h1></li>
<li>最近也有很多场景中出现了加权的L1和L2，即两者的加权求和。或者其他L1和L2的变体，如分段使用L1和L2，在预测值满足一定条件时使用L1计算损失，其他情况下使用L2计算损失。这要由具体的任务来定。<h1 id="L1和L2的函数图像"><a href="#L1和L2的函数图像" class="headerlink" title="L1和L2的函数图像"></a>L1和L2的函数图像</h1><img src="https://img-blog.csdnimg.cn/b3403a2016da4d1d87e4a1f201051567.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lhbnl1eGlhbmd0b2RheQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/10745f39659e47539ee7af9641d8e18a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lhbnl1eGlhbmd0b2RheQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>（图片来自于网络）</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 09】tensorflow和pytorch的相同点和区别</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2009%E3%80%91tensorflow%E5%92%8Cpytorch%E7%9A%84%E7%9B%B8%E5%90%8C%E7%82%B9%E5%92%8C%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<h1 id="相同点"><a href="#相同点" class="headerlink" title="相同点"></a>相同点</h1><ul>
<li>tensorflow和pytorch都是为深度学习提供的开源框架。</li>
<li>都有专门的团队在维护和更新。</li>
<li>社区环境都很好，开源项目、模型很多。<span id="more"></span>
<h1 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h1></li>
<li>两者最主要的区别在于tensorflow是基于静态图构图的，pytorch是基于动态图构图的，这两者的差异主要是框架设计时的思路导致的。</li>
<li>直观来说，tensorflow在搭建框架的时候是没有真正的数据传递的，可以理解为设计模型和运行模型、传递数据是分开的，在调试时无法读取对应op的具体输入输出。</li>
<li>pytorch是基于动态图构图的，可以理解为设计模型和运行模型、传递数据是同步进行的，在调试时断点打在哪里，就能看到具体的对应数据。</li>
<li>通常，tensorflow提供的API更加底层，而pytorch提供的API封装的更为完善，如果想深入进行算子、op的设计，更建议使用tensorflow。如果想快速的搭建模型，比如打比赛时做model fusion等常见操作，则pytroch会让你的速度更快。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 06】inception的提出背景和主要特点</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2006%E3%80%91inception%E7%9A%84%E6%8F%90%E5%87%BA%E8%83%8C%E6%99%AF%E5%92%8C%E4%B8%BB%E8%A6%81%E7%89%B9%E7%82%B9/</url>
    <content><![CDATA[<h1 id="inception的提出背景"><a href="#inception的提出背景" class="headerlink" title="inception的提出背景"></a>inception的提出背景</h1><ul>
<li>inception最早是Google在2014年在GoogLeNet中提出的，在2014年业界的共识是增加模型的参数量可以提高模型精度，那时业界远没触碰到模型复杂度的瓶颈，学者都是通过增加网络深度来堆叠参数的，而google则是通过增加网络的宽度来堆叠参数。<span id="more"></span>
<h1 id="inception的主要特点"><a href="#inception的主要特点" class="headerlink" title="inception的主要特点"></a>inception的主要特点</h1></li>
<li>它的主要特征就是将常用的卷积核：1x1、3x3、5x5和池化操作堆叠在一起，这样让模型自适应的去选择合适的感受野，同时增加了网络的宽度和参数量，在那一年的ImageNet中取得了极好的成绩。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 07】BatchNormalization 的原理和作用</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2007%E3%80%91BN%E7%9A%84%E5%8E%9F%E7%90%86%E5%92%8C%E4%BD%9C%E7%94%A8/</url>
    <content><![CDATA[<p>Batch Normalization也是深度学习中的一个高频词汇，这篇文章将会对其做一个简单介绍。</p>
<span id="more"></span>
<h1 id="1-BN的原理"><a href="#1-BN的原理" class="headerlink" title="1. BN的原理"></a>1. BN的原理</h1><ul>
<li>BN就是在激活函数接收输入之前对数据分布进行规范化，具体计算就是去均值归一化，将数据的分布都规范到标准正态分布中，使得激活函数的输入值落在函数较为敏感的区域，也即梯度较大的区域，从而避免梯度消失、减少训练时间。因此，BN也通常需要放在激活函数之前。<h1 id="2-BN的作用"><a href="#2-BN的作用" class="headerlink" title="2. BN的作用"></a>2. BN的作用</h1></li>
</ul>
<ol>
<li>对数据进行规范化，降低样本之间的差异。</li>
<li>使激活函数的输入落在梯度较大的区域，一个很小的输入差异也会带来较大的梯度差异，可以有效的避免梯度消失，加快网络的收敛。</li>
<li>降低了层与层之间的依赖关系，不加BN的时候当前层会直接接收上一层的输出，而加了BN之后当前层接收的是一些规范化的数据，因此使得模型参数更容易训练，同时降低了层与层之间的依赖关系。<h1 id="3-BN层的可学习参数"><a href="#3-BN层的可学习参数" class="headerlink" title="3. BN层的可学习参数"></a>3. BN层的可学习参数</h1></li>
</ol>
<ul>
<li>scale（γ），即缩放尺度，用于乘以输入进行缩放。</li>
<li>offset（β），即偏移量，用于和输入相加进行偏移。</li>
<li>BN的对象是特征图，因此会以每个特征图为单元取一堆γ和β。<h1 id="4-infer时BN的处理"><a href="#4-infer时BN的处理" class="headerlink" title="4. infer时BN的处理"></a>4. infer时BN的处理</h1></li>
<li>在infer（预测）的时候，γ和β作为一个可学习参数有自己的数值，而计算BN所需要的均值和方差则是训练时统计的平均值。<h1 id="5-BN的具体计算步骤以及公式"><a href="#5-BN的具体计算步骤以及公式" class="headerlink" title="5. BN的具体计算步骤以及公式"></a>5. BN的具体计算步骤以及公式</h1></li>
</ul>
<ol>
<li>求均值。</li>
<li>求方差。</li>
<li>对数据进行标准化（将数据规范到标准正态分布）。</li>
<li>训练参数γ和β。</li>
<li>通过线性变换输出。<br><img src="https://img-blog.csdnimg.cn/e5f2c852e2aa4563bb3199dc892b216b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lhbnl1eGlhbmd0b2RheQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">（图片来源于网络）<h1 id="6-BN和L2参数权重正则化的区别"><a href="#6-BN和L2参数权重正则化的区别" class="headerlink" title="6. BN和L2参数权重正则化的区别"></a>6. BN和L2参数权重正则化的区别</h1></li>
</ol>
<ul>
<li>BN是拉平不同特征图（也可以说是特征）之间的差异，进行去均值归一化。而L2参数权重正则化则没有改变同一层参数的相对大小，而是对当前参数自身进行正则化。</li>
<li>本身每个参数的模长是不同的，而L2参数权重正则化会拉平参数之间的差异，让他们都往0靠近。而BN则不对此产生影响。</li>
<li>对于一个特征图，它们量级、方差可能都不同，而BN就让方差为1，均值为0，从而导致特征图之间的差异减小了。L2参数权重正则化不以此层面为目标产生影响。</li>
<li>L2参数权重正则化是对各个参数权重本身的，而BN是对特征图全局的。</li>
<li>L2参数权重正则化让网络的权重不会过大，而BN的主要目的是加快训练同时防止梯度消失。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 10】图像的梯度</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2010%E3%80%91%E5%9B%BE%E5%83%8F%E7%9A%84%E6%A2%AF%E5%BA%A6/</url>
    <content><![CDATA[<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><ul>
<li>对于图像的梯度，如果理解数学中离散点的梯度求导方法就会发现一点也不神秘。梯度表示的是某一函数在该点处的方向导数沿着这个方向取得最大值，简单来说就是它总指向函数增长最快的方向。<span id="more"></span></li>
<li>一句话概括图像梯度，图像x方向上的梯度就是x方向上两个相邻像素值相减，y方向上的梯度就是y方向上两个相邻像素值相减。<h1 id="特点及含义"><a href="#特点及含义" class="headerlink" title="特点及含义"></a>特点及含义</h1></li>
<li>梯度是一个矢量，也就是既有大小也有方向，因此会加以区分x方向、y方向的正向梯度、反向梯度。</li>
<li>图像的梯度通常反映了图像的纹理信息，纹理发生突变的区域通常会有更高的响应。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 08】dropout的原理、特点以及作用</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2008%E3%80%91dropout%E7%9A%84%E5%8E%9F%E7%90%86%E3%80%81%E7%89%B9%E7%82%B9%E4%BB%A5%E5%8F%8A%E4%BD%9C%E7%94%A8/</url>
    <content><![CDATA[<h1 id="dropout的原理"><a href="#dropout的原理" class="headerlink" title="dropout的原理"></a>dropout的原理</h1><ul>
<li>dropout就是对于每个神经元，都有一定的概率被舍弃，也就是让其输出置零，进而不更新权重。<span id="more"></span>
<h1 id="dropout的特点"><a href="#dropout的特点" class="headerlink" title="dropout的特点"></a>dropout的特点</h1></li>
<li>只在训练的时候开启，验证的时候不开启。</li>
<li>值得注意的是，dropout的舍弃概率是作用到每个神经元上的，并非总共有效的神经元占当前layer的50%（或其他概率），而是当前layer的当前参数有50%（或其他概率）的可能被舍弃。</li>
<li>最早dropout是在全连接层使用的，后来在卷积层中也增加了dropout功能，当前的一些常见框架都有提供相关API。<h1 id="dropout的作用"><a href="#dropout的作用" class="headerlink" title="dropout的作用"></a>dropout的作用</h1></li>
<li>主要用于防止模型过拟合。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 11】什么是景深</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2011%E3%80%91%E4%BB%80%E4%B9%88%E6%98%AF%E6%99%AF%E6%B7%B1/</url>
    <content><![CDATA[<p>在计算机视觉中的一些任务中可能会出现景深的概念，如深度估计、SLAM、视觉里程计等，这篇文章简单介绍一下景深概念。</p>
<span id="more"></span>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><ul>
<li>我们拍照的时候都知道，对焦在相机成像平面上的物体才是清晰的，而物体的对焦平面可以通过相机镜头来控制，同时也与物体和拍摄点之间的距离有关，当我们对焦到距离拍摄点稍远的物体时，近距离的物体就会变得模糊，反之亦然。但是，我们对焦到一个物体之后，可以看到对焦点附近的物体成像也都是清晰的，而它们处于不同的焦平面上，这是为什么呢？因为在焦平面的前后会出现一个弥散斑，这个弥散斑的直观影响就是对焦平面附近的几个焦平面也会有清晰的成像，而能够清晰成像的这一段距离范围，就是景深。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 12】深度估计概述</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2012%E3%80%91%E6%B7%B1%E5%BA%A6%E4%BC%B0%E8%AE%A1%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<p>深度估计是计算机视觉领域中的一个子任务，其目的是获取物体和拍摄点之间的距离，为三维重建、距离感知、SLAM、视觉里程计、活体检测、视频插帧、图像重建等一系列任务提供深度信息。这篇文章会对其做一个简单介绍。</p>
<span id="more"></span>
<h1 id="任务目标"><a href="#任务目标" class="headerlink" title="任务目标"></a>任务目标</h1><ul>
<li>深度估计任务的目标就是获取物体和拍摄点之间的距离，最终会获得一个深度图，也称为光流图，它记录了同一物体在不同图像之间的视差，再通过相机参数、两个拍摄点之间的位置信息即可换算出物体和拍摄点之间的距离。<h1 id="什么是视差（光流）"><a href="#什么是视差（光流）" class="headerlink" title="什么是视差（光流）"></a>什么是视差（光流）</h1></li>
<li>先举一个直观的例子，大家应该都坐过车，在车辆移动时往窗外看去，可以看到远处的物体变化的慢，而近处的物体变化的非常快，这里面蕴含的就是视差信息。</li>
<li>视差也被称为光流，在上面的例子中，随着车辆的移动，假设你在两个连续的时刻各拍了一张图，如果这两张图像中有一些相同的物体，那么这些物体在这两张图像中像素坐标的差异通常是不同的，而如果某个物体在这两张图片中的像素坐标差异非常大，那么由此可判断这个物体离拍摄点相对较近，而如果某个物体在这两张图像中的像素坐标差异较小，那么可以推断出这个物体距离拍摄点相对较近，也就是说，较近的物体视差较大，较远的物体视差较小，而同一物体在不同图像中的像素坐标差异，就是视差。<h1 id="深度估计的应用场景"><a href="#深度估计的应用场景" class="headerlink" title="深度估计的应用场景"></a>深度估计的应用场景</h1></li>
<li>视差的主要作用是获取物体的深度信息，也就是和拍摄点之间的距离。</li>
<li>在三维重建任务中，可以由此深度获取物体的三维点云图，然后进行三维重建。</li>
<li>在距离感知任务中，如基于视觉的自动驾驶中，可以由此判断场景内各物体和车辆之间的距离，进而辅助车辆进行决策。</li>
<li>在SLAM、视觉里程计中，能够基于深度、感知融合进行道路信息的采集，谷歌街景、滴滴街景等就用到了这个技术，还有一些自动驾驶企业如waymo、地平线、momenta、图森未来等都离不开这个技术。</li>
<li>在人脸的活体检测中，可以判断目标是一个真实的人脸还是一个平面照片。虽然可能拿3D头模没办法，不过通常基于深度的活体检测已经能筛选掉一大批假人脸了。</li>
<li>在视频插帧、图像重建中，可以用于补齐新的图像，提升用户看视频或者图像的主观感受，或者模拟360度全景拍摄。<h1 id="获取深度信息的方法"><a href="#获取深度信息的方法" class="headerlink" title="获取深度信息的方法"></a>获取深度信息的方法</h1></li>
<li>传统方法一般是立体匹配，也就是通过搜索和算子的匹配找到两张图像中的统一像素点，然后输出他们之间像素坐标的差异。</li>
<li>基于EPI图像和重对焦图像的深度估计，在多视点任务中，EPI图像和重对焦图像也是两个常见的概念，EPI图像中每条线的斜率、重对焦图像中每个像素点的清晰度，都蕴含了深度信息。</li>
<li>雷达。关注自动驾驶的都知道，完成自动驾驶有两种方法，一种是特斯拉和传统车企的路子，也就是在车辆上装一些摄像头，通过摄像头和算法来感知深度，现在由于精度的问题，业界对其的共识是这种方法只能达到辅助驾驶，无法实现完全的自动驾驶。另一种做法则是以谷歌为代表的完全自动驾驶方向，标志是舍弃了方向盘、车辆顶部装有一个不断旋转的巨大雷达，这里不深究技术细节，只要知道这种方法的精度更高即可。</li>
<li>结构光。这也是一种基于光学特性获取物体深度的方法，不过没有大面积普及，不做赘述。<h1 id="深度学习和传统方法比的优势"><a href="#深度学习和传统方法比的优势" class="headerlink" title="深度学习和传统方法比的优势"></a>深度学习和传统方法比的优势</h1></li>
<li>从算法层面说，主要优势就是精度高、数据信息使用的更加充分，深度学习模型自己拟合的高纬度函数要优于手工设计的能量函数。</li>
<li>从应用侧角度看，一个明显的优势是在达到需求的前提下，落地成本较低。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 14】group convolution</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2014%E3%80%91group%20convolution/</url>
    <content><![CDATA[<p>group convolution又称为组卷积，是一种常见的降低计算量的方法。</p>
<span id="more"></span>
<h1 id="计算方式"><a href="#计算方式" class="headerlink" title="计算方式"></a>计算方式</h1><ul>
<li>首先要将通道进行分组，然后对每一组进行卷积，卷积之后再进行通道的叠加<h1 id="带来的问题"><a href="#带来的问题" class="headerlink" title="带来的问题"></a>带来的问题</h1></li>
<li>这种方法一定程度上失去了通道之间的联系，导致通道之间的相关性减弱，并且非常依赖与分组超参的设置。因此后续就有人提出了shuffle net来解决这个问题，也就是在进行组卷机分组之前随机打算每个通道，这样可以增大随机性，提升模型的鲁棒性。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 17】模型不收敛的原因以及处理方法</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2017%E3%80%91%E6%A8%A1%E5%9E%8B%E4%B8%8D%E6%94%B6%E6%95%9B%E7%9A%84%E5%8E%9F%E5%9B%A0%E4%BB%A5%E5%8F%8A%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>模型不收敛通常指模型在训练过程中无法收敛，这并不能说明模型无效，可以从以下几个方面分析。</p>
<span id="more"></span>
<h1 id="模型不收敛的原因以及处理方法"><a href="#模型不收敛的原因以及处理方法" class="headerlink" title="模型不收敛的原因以及处理方法"></a>模型不收敛的原因以及处理方法</h1><ul>
<li>数据量过大，而模型过小。</li>
<li>学习率设置过大，导致了loss震荡，进而导致模型无法收敛。</li>
<li>数据分布较为复杂，没有进行归一化设置，导致每次迭代模型都往不同的方向上优化。</li>
<li>可能出现了梯度爆炸或者梯度消失，可以看<a href="https://blog.csdn.net/yanyuxiangtoday/article/details/119789602?spm=1001.2014.3001.5502">梯度消失和梯度爆炸的解决方法</a>.</li>
<li>代码是不是有bug，导致迭代的时候优化器没有进行参数的更新。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 19】VGG为什么使用3x3的卷积核</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2019%E3%80%91VGG%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A83x3%E7%9A%84%E5%8D%B7%E7%A7%AF%E6%A0%B8/</url>
    <content><![CDATA[<p>VGG为什么选择3x3的卷积核，这个问题是算法面试的高频问题。</p>
<span id="more"></span>
<ul>
<li>因为通过串联两个3x3的卷积核可以达到5x5卷积核的感受野，同时降低了模型的参数量。并且多个3x3卷积核的串联有更多的激活函数，有更强的非线性表达能力。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 18】图像锐化和平滑的概念以及使用场景</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2018%E3%80%91%E5%9B%BE%E5%83%8F%E9%94%90%E5%8C%96%E5%92%8C%E5%B9%B3%E6%BB%91%E7%9A%84%E6%A6%82%E5%BF%B5%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/</url>
    <content><![CDATA[<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><ul>
<li>锐化就是通过增强图像的高频信息，也就是纹理边缘来减少图像中的模糊细节，但是在增强纹理的时候也引入了图像噪声。<span id="more"></span></li>
<li>平滑与锐化相反，它是为了过滤掉高频分量，可以减少图像的噪声，但是可能会使得图像变得模糊。<h1 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h1></li>
<li>在计算机视觉的一些任务中，涉及到图像重建的、如高精度的深度估计、医学图像分割、三维重建等任务，最终需要得到原始图像分辨率大小的输出，同时对图像的边缘清晰度也有较高的要求，这时候可以通过增强特征图中的高频分量，在计算损失函数的时候放大这些区域的损失，进而放大对应参数的梯度，使得网络往更突出边缘的方向上优化。</li>
<li>与上相反，如果是一些希望输出更加平滑的任务，则可以考虑对特征图进行平滑操作，进而减小高频区域的损失，减小对应参数的梯度，使得网络往更平滑的方向上优化，通常这种技术都会用在smooth loss中。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 16】空洞卷积的概念以及使用场景</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2016%E3%80%91%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF%E7%9A%84%E6%A6%82%E5%BF%B5%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/</url>
    <content><![CDATA[<p>空洞卷积（dilated convolution）也是一种常见的卷积方式，主要目标是在不提升计算量和降低特征图分辨率的情况下获得更大的感受野。</p>
<span id="more"></span>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><ul>
<li>空洞卷积就是在卷积的时候不是对连续的值进行计算，而是会中间隔开几个值，其他与普通的卷积并无差异。可以理解为一个稀疏的大卷积核，只有个别值有效，其余值为零。<h1 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h1></li>
<li>在不增加计算量和降低特征图分辨率的情况下增大感受野。<h1 id="问题和解决方法"><a href="#问题和解决方法" class="headerlink" title="问题和解决方法"></a>问题和解决方法</h1></li>
<li>空洞卷积的主要问题也是它的主要特点，就是卷积核不连续，最终可能会导致并非特征图中的所有点都能参与计算，这也会丢失信息的连续性，尤其是对于像素级的任务（如图像分割）来说非常不适用。并且这种设计主要针对在原始图像中占有更多像素点的较大物体，而对于较小的物体可能会失效，因为小物体并不需要较大的感受野。</li>
<li>对于上述问题的一种解决方法就是将一组空洞卷积的dilation rate设计成一个没有大于1的公约数的数值，也就是锯齿状的空洞卷积，如[1,2,5,1,2,5]这样的循环结构，这样就可以保证在每一个循环中所有的像素点都能参与计算。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 20】ReLU的特点和使用场景</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2020%E3%80%91ReLU%E7%9A%84%E7%89%B9%E7%82%B9%E5%92%8C%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/</url>
    <content><![CDATA[<p>ReLU是深度学习任务中常见的激活函数，这里简单介绍它的特点和使用场景。</p>
<span id="more"></span>
<h1 id="ReLU的特点"><a href="#ReLU的特点" class="headerlink" title="ReLU的特点"></a>ReLU的特点</h1><ul>
<li>ReLU是一个分段函数，当输入小于零的时候，输出为零，当输入大于零的时候，将输入值作为输出。<h1 id="ReLU的使用场景"><a href="#ReLU的使用场景" class="headerlink" title="ReLU的使用场景"></a>ReLU的使用场景</h1></li>
<li>主要用于避免梯度消失和梯度爆炸。对于梯度消失，因为sigmoid的梯度最大值只有0.25，在链式求导过程中可能就会导致梯度消失，而ReLU在激活函数大于零的时候梯度恒为1，因此可以有效避免梯度消失和梯度爆炸的现象。<a href="https://blog.csdn.net/yanyuxiangtoday/article/details/119789602?spm=1001.2014.3001.5501">点我看梯度消失和梯度爆炸的概念和解决方案</a></li>
<li>另一方面，采用ReLU激活函数能够使得网络的收敛速度加快。</li>
<li>但是如果说希望网络最后输出一张图片，那么肯定是希望这张图像的像素在0到1之间，这个时候仍然可以在输出层采用sigmoid激活函数，将网络的输出限制到0到1之间。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 13】smooth loss</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2013%E3%80%91smooth%20loss/</url>
    <content><![CDATA[<p>smooth loss通常用在各种图像重建任务中主要解决平滑问题，如图像分割、深度估计、视频插帧等。</p>
<span id="more"></span>
<h1 id="常见的计算方法"><a href="#常见的计算方法" class="headerlink" title="常见的计算方法"></a>常见的计算方法</h1><ul>
<li>通常smooth loss都是先计算目标图像在x方向和y方向上的梯度，然后用目标图像的梯度乘以原始图像梯度的对数，再对结果进行reduce_mean就得到了smooth loss，用于保证目标图像的梯度不能过大，进而保证看起来更加平滑。在如医学图像重建的任务重是非常必要的一项。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 22】sigmoid、tanh、relu激活函数</title>
    <url>/2021/09/12/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2022%E3%80%91sigmoid%E3%80%81tanh%E3%80%81relu%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<p>sigmod、tanh、relu都是深度学习任务中常见的激活函数，主要作用是让模型获得非线性表达能力，这篇文章简单对它们做一个介绍。</p>
<span id="more"></span>
<h1 id="sigmoid"><a href="#sigmoid" class="headerlink" title="sigmoid"></a>sigmoid</h1><ul>
<li>sigmoid激活函数的取值分布在0到1之间，在深度学习再度被人们关注的初期是最常被采用的激活函数，但是由于网络层数的加深，采用sigmoid激活函数常常会导致梯度消失。另外，它的均值是0.5，并不是以0为中心的，因此也不便于计算。</li>
<li>但是如果在输出层想将输出规范到0到1之间，那么就可以直接采用sigmoid激活函数。相应的，想得到其他输出只需要在乘以缩放系数并加上偏置即可。<h1 id="tanh"><a href="#tanh" class="headerlink" title="tanh"></a>tanh</h1></li>
<li>tanh激活函数取值在-1到1，它的均值为0，弥补了sigmoid均值非0的缺点，但是和sigmoid激活函数一样可能在深层网络中导致梯度消失。<h1 id="relu"><a href="#relu" class="headerlink" title="relu"></a>relu</h1></li>
<li>relu主要是为了解决梯度消失和梯度爆炸问题产生的，它是一个分段函数，当小于0的时候梯度恒为0，大于0的时候梯度恒为1，因此不会出现产生梯度消失或梯度爆炸问题。并且由于将负数全部置零了也会因为降低了乘加器的调用从而加快模型推理的速度，只是受益并不大。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 21】加快模型训练速度的方法</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2021%E3%80%91%E5%8A%A0%E5%BF%AB%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E9%80%9F%E5%BA%A6%E7%9A%84%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>在深度学习任务中，虽然可以通过堆叠参数、设计更复杂的结构来提高模型的表征能力，但这也会导致模型的计算量增加，训练时间延长，大大降低模型的产出效率。这篇文章根据博主的经验简单介绍一些加快模型训练速度的方法，以及为什么需要关注模型的训练速度。</p>
<span id="more"></span>
<h1 id="加快深度学习模型训练速度的方法"><a href="#加快深度学习模型训练速度的方法" class="headerlink" title="加快深度学习模型训练速度的方法"></a>加快深度学习模型训练速度的方法</h1><h2 id="1-合理的超参数设计"><a href="#1-合理的超参数设计" class="headerlink" title="1. 合理的超参数设计"></a>1. 合理的超参数设计</h2><ul>
<li>BatchSize。每次迭代batch的大小是影响每次推理速度的主要因素，而batchsize并非越大越好，一个经验性的可选数值是32、64、128，一般来说，每个batch的大小一旦超过64，继续增大batch带来的性能收益就微乎其微了，因此可以通过实验尝试一下这三个数值，在达到同样的性能前提下让batch尽可能的小，这也会给显存留下更大的空间，进而可以尝试更多的模型设计方式。</li>
<li>epoch、学习率策略。迭代次数和学习率这两个参数需要放在一起讲，我们在挑选这两个参数时，需要每100次迭代（或者其他）保存一次模型，然后把这些模型的精度曲线、loss、和当前的学习率画到一张图像中。从图像中就可以发现，在某些学习率设置下，可能训练几个epoch模型的性能就不会继续增加了，loss也不会降低，因此找到这个平衡点之后就可以将当前学习率下的后续epoch舍弃掉，进一步降低学习率训练。一个经验性的总结是：更小的学习率通常只需要更少的epoch。因此，可以通过修改学习率和训练epoch的策略来达到相同精度的前提下降低训练时间。<h2 id="2-权值共享"><a href="#2-权值共享" class="headerlink" title="2. 权值共享"></a>2. 权值共享</h2></li>
<li>每轮迭代的推理速度和模型的参数量、计算量息息相关，而通过设置参数权值共享，可以降低总的参数量和计算量，另外如tensorflow，pytorch等深度学习框架都有针对权值共享的推理优化，所以会有相对明显的加速效果。<h2 id="3-升级相关软件包"><a href="#3-升级相关软件包" class="headerlink" title="3. 升级相关软件包"></a>3. 升级相关软件包</h2></li>
<li>如将cuda、tensorflow、pytorch进行升级，一般来说越新越好。旧版cuda可能只是针对一些显卡做了适配，但是新版cuda会针对一些新的算子、显卡做针对性优化，如常见的Tesla V系列显卡，采用cuda11的推理速度就明显快于cuda8、9。tensorflow、pytorch等框架也是同理。并且这些软件包都是向下兼容的，因此不用过于担心代码移植问题。<h2 id="4-多卡训练、数据并行"><a href="#4-多卡训练、数据并行" class="headerlink" title="4. 多卡训练、数据并行"></a>4. 多卡训练、数据并行</h2></li>
<li>在采用NVIDIA GPU进行训练的时候，可以通过<code>$ watch -n 0.1 nvidia-smi</code>命令时刻观察GPU显存和利用率情况，只有当GPU 利用率处于高位的时候GPU才是在高效的工作，否则大部分时间都是在闲置，而这一般是由于数据读取过慢导致的。可以通过自己实现多线程读数据或者采用tensorflow、pytorch等框架提供的并行读数据的方法让GPU保持较高利用率，从而减少GPU等待时间，降低整体训练耗时。<h2 id="5-混合精度训练"><a href="#5-混合精度训练" class="headerlink" title="5. 混合精度训练"></a>5. 混合精度训练</h2></li>
<li>通常参数都是采用float32进行计算的，而将参数保存为float16格式理论上能加快一倍的训练速度并且节省一倍的模型大小，同时精度损失不会太多，这就是混合精度训练方法。具体细节可以参照常见的深度学习框架提供的混合精度训练包。<h1 id="加快模型训练速度的价值"><a href="#加快模型训练速度的价值" class="headerlink" title="加快模型训练速度的价值"></a>加快模型训练速度的价值</h1>最后简单说一下为什么应该关注模型训练速度。</li>
<li>提高效率。不管是对于科研还是比赛，亦或者是实际的工作，模型的产出速度都极大的影响了实验的效率，有人需要一周才能出一个模型，而通过上述策略加快模型训练速度，可以将该时间降低到1天或者更快，这其中的价值不言自明。</li>
<li>省钱。不管是企业还是高校实验室，GPU显卡或是买来的，或是租来的。如果采用的是腾讯云的GPU服务器，腾讯云和阿里云常被选择的企业级的GPU服务器价格通常是20,000~30,000/月，按照20,000/月计算每小时租金为28元，如果产出一个模型需要7天，那么一个模型的成本是4,704元，按照每10个模型产出一个有效模型来算，那么一个有效模型的成本就是47,040元，如果将模型训练时间缩短三倍，那么一个有效模型成本就缩短到了15,680元，节省31,360元，按照100个研究员/工程师每个月产出两个有效模型，每100个研究员/工程师一个月就节省了6,272,000元，也就是六百多万，不得不说AI部门的运营成本是真滴高。</li>
<li>提高效率，节省时间。对于在校生做研究、打比赛来说，提高效率和模型产出，就能有更多实验数据和做更多尝试，或许paper就发出来了，比赛就拿名次了。对于企业来说，本质上还是省钱，把用人成本、运营成本都算上，提高效率就是大把大把的省钱。</li>
</ul>
<p>所以，做实验的时候一定要考虑好效率问题，提高模型的训练速度。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 23】深度学习中常用的优化器</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2023%E3%80%91%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E4%BC%98%E5%8C%96%E5%99%A8/</url>
    <content><![CDATA[<p>深度学习任务中一般都采用优化器来决定模型的梯度更新算法，本文简单对常用的优化器做个简单介绍。</p>
<span id="more"></span>
<h1 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h1><ul>
<li>SGD（stochastic gradient descent）随机梯度下降：单条数据就可以对参数进行一次更新。优点是参数更新快，缺点是每次更新采用的数据量小，容易震荡。<h1 id="BGD"><a href="#BGD" class="headerlink" title="BGD"></a>BGD</h1></li>
<li>BGD（batch gradient descent）批量梯度下降：所有数据都参与参数的每一次更新。优点是梯度更新平滑，缺点是参数更新较慢。<h1 id="MBGD"><a href="#MBGD" class="headerlink" title="MBGD"></a>MBGD</h1></li>
<li>MBGD（min-batch gradient descent）小批量梯度下降：每次更新都只取数据中的一部分参与运算，是目前最常见的梯度更新策略。有点事相随与随机梯度下降，梯度更新更加平滑，且不会像BGD一样参数更新缓慢。但是需要制定每个batch中的数据均衡策略保证训练不会出现震荡。<h1 id="momentum"><a href="#momentum" class="headerlink" title="momentum"></a>momentum</h1></li>
<li>主要解决随机梯度下降时的震荡问题，通过加入一个momentum参数，以本次计算得到的梯度和上次梯度更新的加权和作为本次要更新的梯度，加速网络收敛，同时抑制震荡，但是有可能难以找到最优点，因此在模型训练的后期通常会将其关闭。<h1 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h1></li>
<li>Adagrad（adaptive gradient algorithm），实际上是在梯度更新时依据每个参数的重要程度对其进行自适应加权，具体做法是将低频的参数和高频的参数分开处理，对低频参数做较大的更新，高频参数进行较小的更新。可以不用手动调节学习率，但是最红学习率会变得非常小。<h1 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h1></li>
<li>主要解决Adagrad学习率会急剧下降的问题。<h1 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h1></li>
<li>Adam（adaptive moment estimation）是目前最常被采用的优化器，是每个参数自适应学习率的方法。相当于RMSprop和momentum的结合。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 24】1x1卷积核的作用和使用场景</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2024%E3%80%911x1%E5%8D%B7%E7%A7%AF%E6%A0%B8%E7%9A%84%E4%BD%9C%E7%94%A8%E5%92%8C%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/</url>
    <content><![CDATA[<p>1x1卷积核虽然不能增加特征的感受野，但仍然常被采用，本文简单介绍它的几点作用。</p>
<span id="more"></span>
<h1 id="1x1卷积核的作用和使用场景"><a href="#1x1卷积核的作用和使用场景" class="headerlink" title="1x1卷积核的作用和使用场景"></a>1x1卷积核的作用和使用场景</h1><ul>
<li>降低通道数。模型的计算计算量和复杂度与每一层的通道数息息相关，如果想要降低某一层的通道数同时又想对特征进行一次组合，那么就可以采用1x1的卷积核。</li>
<li>多通道整合。降低通道数的同事又可以进行一次通道整合，通常见于网络或者块的输出增，特征通过concat之后通常需要一次信息的整合，这个时候就可以采用1x1的卷积核。</li>
<li>实现通道数的改变。在某些层中，可能希望实现通道数的增加而不是减少，这个时候又不想增加太多的计算量，就可以采用1x1的卷积核来完成。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 25】提升模型泛化能力的方法</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2025%E3%80%91%E6%8F%90%E5%8D%87%E6%A8%A1%E5%9E%8B%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%E7%9A%84%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h1 id="提升模型泛化能力的方法"><a href="#提升模型泛化能力的方法" class="headerlink" title="提升模型泛化能力的方法"></a>提升模型泛化能力的方法</h1><span id="more"></span>
<ul>
<li>从数据角度上来说。可以通过数据增强、扩充训练集等方法提高泛化能力。</li>
<li>在训练策略上，可以增加每个batch size的大小，进而让模型每次迭代时见到更多数据，防止过拟合。</li>
<li>调整数据分布，做训练数据集的类别均衡。</li>
<li>调整网络结构。如果数据集较小，可以降低模型复杂度防止过拟合。如果数据集较大，可以尝试更加复杂的模型。</li>
<li>减少过拟合的方法也可以提升模型的泛化能力。<a href="https://blog.csdn.net/yanyuxiangtoday/article/details/119790029?spm=1001.2014.3001.5502">点我看过拟合和欠拟合的概念及解决方案</a></li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 27】单目SLAM中的尺度漂移</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2027%E3%80%91%E5%8D%95%E7%9B%AESLAM%E4%B8%AD%E7%9A%84%E5%B0%BA%E5%BA%A6%E6%BC%82%E7%A7%BB/</url>
    <content><![CDATA[<h1 id="单目SLAM中的尺度漂移是什么"><a href="#单目SLAM中的尺度漂移是什么" class="headerlink" title="单目SLAM中的尺度漂移是什么"></a>单目SLAM中的尺度漂移是什么</h1><ul>
<li>在使用单目相机估计相机姿态和3D坐标时，需要对极几何、三角化估计，这个过程中会产生累积误差，进而导致尺度的不一致，产生尺度漂移。</li>
<li>单目SLAM产生尺度漂移的根本原因是单目相机无法根据一张图片就会的图中物体的大小信息，这就是尺度漂移的根源。<span id="more"></span>
<h1 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h1></li>
<li>将前后两帧的尺度作为后续的尺度。</li>
<li>采用全局式估计，使用统一的尺度。</li>
<li>使用双目相机，增加一个额外的图像用于确定尺度。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 26】相机的内参、外参以及像素坐标和世界坐标的转换</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2026%E3%80%91%E7%9B%B8%E6%9C%BA%E7%9A%84%E5%86%85%E5%8F%82%E3%80%81%E5%A4%96%E5%8F%82%E4%BB%A5%E5%8F%8A%E5%83%8F%E7%B4%A0%E5%9D%90%E6%A0%87%E5%92%8C%E4%B8%96%E7%95%8C%E5%9D%90%E6%A0%87%E7%9A%84%E8%BD%AC%E6%8D%A2/</url>
    <content><![CDATA[<p>计算机视觉中的深度估计、SLAM、三维重建任务通常会用到相机参数作为输入，本文将对其进行简单介绍。</p>
<span id="more"></span>
<h1 id="相机的内参"><a href="#相机的内参" class="headerlink" title="相机的内参"></a>相机的内参</h1><ul>
<li>相机的内参矩阵包含x方向的焦距fx和y方向的焦距fy。以及相机光轴在x方向和y方向上的偏移量cx,cy。<br><img src="https://img-blog.csdnimg.cn/2a1647c9b9cf4dbaa3b16e9c12de955a.png" alt="在这里插入图片描述"></li>
<li>内参为什么有两个焦距<ul>
<li>一般来说，一个物体的宽度和高度会随着各个物体与相机之间的距离增加按照比例变小。而对于一张矩形的图片，物体的高宽变小的比例是不同的，这个比例就是根据焦距得到的，因此会有x方向和y方向各自的焦距。如下图公式：<br><img src="https://img-blog.csdnimg.cn/5d18dde8e5d147ac94405e4894d45d53.png" alt="在这里插入图片描述"><h1 id="相机的外参"><a href="#相机的外参" class="headerlink" title="相机的外参"></a>相机的外参</h1></li>
</ul>
</li>
<li>相机的外参也被称为旋转平移矩阵，包括xyz三个轴的旋转参数，即旋转矩阵（R矩阵）。还有三个轴的平移参数，也就是平移矩阵（T矩阵）。<h1 id="像素坐标和世界坐标的转换"><a href="#像素坐标和世界坐标的转换" class="headerlink" title="像素坐标和世界坐标的转换"></a>像素坐标和世界坐标的转换</h1></li>
<li>相机的外参通常用于像素空间到世界坐标的转换。公式如下图，其中（u, v）是像素坐标，(x, y, z）是世界坐标。<br><img src="https://img-blog.csdnimg.cn/0c542181557e473899cad3acca0527b4.png" alt="在这里插入图片描述"><br>简化后得到：<br><img src="https://img-blog.csdnimg.cn/c79432ece09c45b2b086c1d477c5fd85.png" alt="在这里插入图片描述"></li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 29】基于深度图的三维重建概述</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2029%E3%80%91%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%9B%BE%E7%9A%84%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<p>三维重建是计算机视觉立体几何方向的主要任务，本文会对基于深度图的三维重建流程做一个简单概述。</p>
<span id="more"></span>
<h1 id="1-获取深度图以及尺度信息"><a href="#1-获取深度图以及尺度信息" class="headerlink" title="1. 获取深度图以及尺度信息"></a>1. 获取深度图以及尺度信息</h1><ul>
<li>第一步，是获取深度图以及尺度信息，如果是结构化的双目相机，就可以直接通过深度估计得到尺度关系，如果是多视角相机，就可以通过深度估计加上相机位姿估计得到尺度关系。</li>
<li>关于其他深度估计的方法，可以参考我的另一篇文章<a href="https://blog.csdn.net/yanyuxiangtoday/article/details/119812203">深度估计概述</a>。<h1 id="2-将像素坐标转换为世界坐标"><a href="#2-将像素坐标转换为世界坐标" class="headerlink" title="2. 将像素坐标转换为世界坐标"></a>2. 将像素坐标转换为世界坐标</h1></li>
<li>像素坐标通过相机的内参矩阵以及第一步获得的尺度关系，可以直接得到基于这个相机的世界坐标信息。</li>
<li>更多细节可以参考我的另一篇文章<a href="https://blog.csdn.net/yanyuxiangtoday/article/details/119849286">相机的内参、外参以及像素坐标和世界坐标的转换</a><h1 id="3-通过RT矩阵转换到世界坐标并得到点云"><a href="#3-通过RT矩阵转换到世界坐标并得到点云" class="headerlink" title="3. 通过RT矩阵转换到世界坐标并得到点云"></a>3. 通过RT矩阵转换到世界坐标并得到点云</h1></li>
<li>经过第二步获得不同相机的世界坐标结果，接下来可以通过RT矩阵融合到同一个世界坐标系下，进而就能得到点云信息。<h1 id="4-获得三角面片"><a href="#4-获得三角面片" class="headerlink" title="4. 获得三角面片"></a>4. 获得三角面片</h1></li>
<li>得到点云之后，就可以根据它的法线方向得到三角面片，再将图像的纹理信息填充到三角面片的顶点上，就完成了三维重建。</li>
<li>其中，法线方向的获取方法是：确定三维点之后，从相机中心发出的射线的反方向就是它的法线方向。<h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h1></li>
<li>以上介绍的是基于深度图的三维重建方法，其实还有其他方法如将三维重建过程分解成一个个的子任务，包括通过图像估计出物体的深度、轮廓、法向图等，然后基于这些信息完成三维重建等。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 28】三维重建中的点云、体素、mesh</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2028%E3%80%91%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E4%B8%AD%E7%9A%84%E7%82%B9%E4%BA%91%E3%80%81%E4%BD%93%E7%B4%A0%E3%80%81mesh/</url>
    <content><![CDATA[<p>点云、体素和mesh都是三维重建中常用的三维物体的表示方法，这篇博客简单做个介绍。</p>
<span id="more"></span>
<h1 id="1-点云"><a href="#1-点云" class="headerlink" title="1. 点云"></a>1. 点云</h1><h2 id="1-1-点云的概念"><a href="#1-1-点云的概念" class="headerlink" title="1.1 点云的概念"></a>1.1 点云的概念</h2><ul>
<li>点云是不规则的数据结构，就是用一堆点来表示物体，这种方法的限制是点与点之间没有联系，缺乏物体的表面信息。<h2 id="1-2-点云的表示方法"><a href="#1-2-点云的表示方法" class="headerlink" title="1.2 点云的表示方法"></a>1.2 点云的表示方法</h2></li>
<li>点云一般采用NxNxN的三维矩阵，或编码xyz三个通道的栅格数据，或以深度图的方式进行表示。<h1 id="2-体素"><a href="#2-体素" class="headerlink" title="2. 体素"></a>2. 体素</h1><h2 id="2-1-体素的概念"><a href="#2-1-体素的概念" class="headerlink" title="2.1 体素的概念"></a>2.1 体素的概念</h2></li>
<li>体素就相当于图像中的像素，可以理解为三维物体中的像素，这就使得三维空间中的物体可以基于规则的空间体素进行表示，进而将图像领域的框架挪用到三维领域，使用3D卷积等方式直接对体素进行处理，缺点是会消耗大量的计算资源，因此限制了体素的分辨率。<h2 id="2-2-体素的表示方法"><a href="#2-2-体素的表示方法" class="headerlink" title="2.2. 体素的表示方法"></a>2.2. 体素的表示方法</h2></li>
<li>SDF（signed distance field）即有效距离场。也就是通过给每个体素赋予SDF来模拟物体表面。如果SDF值大于0，表示该体素在当前表面前，如果SDF值小于0，则表示体素在表面后，SDF越接近0，表明它越接近场景真实表面。不过这种表示方法会占用大量的资源，因此有人提出了TSDF。</li>
<li>TSDF是为了降低体素表示方法的资源消耗而提出的。TSDF采用栅格立方体代表三维空间，每个栅格中存放的是其到物体表面的距离，TSDF值的政府分别表示被表面遮挡与可见，而表面上的点则经过零点。<h1 id="3-mesh"><a href="#3-mesh" class="headerlink" title="3. mesh"></a>3. mesh</h1></li>
<li>理解了点云就理解了mesh，因为mesh就是点云的升级版，可以将点云的信息表示的更精细，可以理解为一种可视化方法。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 15】反卷积的概念以及使用场景</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2015%E3%80%91%E5%8F%8D%E5%8D%B7%E7%A7%AF%E7%9A%84%E6%A6%82%E5%BF%B5%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/</url>
    <content><![CDATA[<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><ul>
<li>反卷积（deconv）是输入一张小的特征图，输出一张大的特征图。首先会对特征图进行padding，然后就可以像正常卷积操作一样进行计算。</li>
<li>反卷积比正常卷积增加了一个参数，叫做output_shape，这是由于不同的特征图，如5x5和6x6的特征图在进行3x3的卷积之后都会得到3x3的特征图，因此反卷积的时候就需要输入一个参数用于指定输出的特征图尺寸。<span id="more"></span>
<h1 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h1></li>
<li>通常在一些图像重建任务中，主要目的是对特征图进行放大，如一些分割任务、图像重建任务等，当通过一个backbone进行特征提取之后需要恢复到原始的分辨率，这个时候就可以采用deconv来计算。另一种常见的方法就是直接进行upsample对图像进行插值，然后进行正常的卷积，具体使用哪一种还要结合任务目标来设计和实验。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 31】出现nan值的处理</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2031%E3%80%91%E5%87%BA%E7%8E%B0nan%E5%80%BC%E7%9A%84%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<p>在深度学习模型训练的时候loss可能会出现nan，本文简要介绍几个可能导致nan出现的原因。</p>
<span id="more"></span>
<ol>
<li>最可能的原因就是除0，可以找一下模型进行数学计算时的除数是否为0，一些函数出现下溢时也会输出0，定位问题之后可以给除数加一个极小值。</li>
<li>log(0)，对数函数的输入如果为0也会导致输出nan，也是可以给输入加一个极小值。</li>
<li>检查数据集。输入数据损坏的时候可能也会出现nan，这个时候现象就是nan偶尔会出现，或者说模型训练着训练着在某一次迭代之后突然就nan了，这都可能是数据问题导致的。</li>
<li>重新进行权重初始化。有时候权重随机初始化时一连串的数据初始化都过大，就会导致最终计算结果nan，因此可以重新随机初始化一次权重尝试。</li>
<li>梯度截断。可能是因为梯度过大，导致更新之后权重过大，一连串的累积之后就会导致最终结果nan，因此可以从梯度截断的角度尝试。</li>
<li>减少学习率。和梯度截断的考虑角度相同，不赘述。</li>
</ol>
<p>模型训练出现nan是一个很令人头疼的问题，以上6个解决思路需要逐一尝试，最终定位当前任务中出现nan的原因并解决。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 34】多进程与多线程的概念与联系</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2034%E3%80%91%E5%A4%9A%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%A6%82%E5%BF%B5%E4%B8%8E%E8%81%94%E7%B3%BB/</url>
    <content><![CDATA[<p>在训练深度学习模型时，速度瓶颈通常出现在加载数据的阶段，一种加速方法是将数据预先组织为npy文件或者tfrecord文件，但是这会将数据所耗费的磁盘空间直接加倍，另一种做法就是通过多进程将数据加载到一个队列中，而每次读取则直接取用这个队列中的元素，这样就可以减少模型等待数据加载的时间，提高模型的训练速度，本文就对多进程、多线程做一个简单介绍。</p>
<span id="more"></span>
<h1 id="多进程和多线程的概念与联系"><a href="#多进程和多线程的概念与联系" class="headerlink" title="多进程和多线程的概念与联系"></a>多进程和多线程的概念与联系</h1><ul>
<li>一个程序至少有一个进程，一个进程至少有一个线程。</li>
<li>线程的划分尺度小于进程，所以多线程程序并发性较高。</li>
<li>进程在执行的时候拥有独立的内存单元。而一个进程中的多个线程是共享内存的，所以可以共享一些变量，但是同一时刻只能有一个线程操作共享内存。</li>
<li>在同一个程序中，多线程可以并发执行一个程序的不同部分。</li>
<li>多进程是多CPU并行调度的。</li>
<li>多线程是同一个进程下执行的，可以被抢断或者挂起。</li>
<li>由于GIL锁的存在，python中其实并没有真正的多线程，即当一个线程使用共享内存时，其他线程必须等待它使用结束才能使用。</li>
<li>IO密集型、多核多机分布式可以使用多进程。</li>
<li>计算密集型、需要频繁创建销毁的，可以使用多线程。<h1 id="多进程和多线程的比较"><a href="#多进程和多线程的比较" class="headerlink" title="多进程和多线程的比较"></a>多进程和多线程的比较</h1></li>
<li>下表对多进程和多线程做了个简单的比较，使用多进程还是多线程要根据实际需求选择。</li>
</ul>
<table>
<thead>
<tr>
<th>对比</th>
<th>多进程</th>
<th>多线程</th>
</tr>
</thead>
<tbody><tr>
<td>数据共享、同步</td>
<td>数据共享复杂，同步简单</td>
<td>数据共享简单，同步复杂</td>
</tr>
<tr>
<td>内存、CPU使用</td>
<td>占用内存多，切换复杂，CPU利用率低</td>
<td>占用内存少，切换简单，CPU利用率高</td>
</tr>
<tr>
<td>创建、销毁、切换</td>
<td>复杂、速度慢</td>
<td>简单、速度快</td>
</tr>
<tr>
<td>编程、调试</td>
<td>编程简单，调试简单</td>
<td>编程复杂，调试复杂</td>
</tr>
<tr>
<td>可靠性</td>
<td>进程间不会相互影响，但是错误的关闭可能会导致僵尸进程</td>
<td>一个线程挂掉全部都会挂掉</td>
</tr>
<tr>
<td>分布式</td>
<td>适用于多核多机分布式</td>
<td>适用于多核</td>
</tr>
<tr>
<td>python包名称</td>
<td>multiprocessing</td>
<td>threading，_thread(已废弃)</td>
</tr>
</tbody></table>
<h1 id="GIL锁"><a href="#GIL锁" class="headerlink" title="GIL锁"></a>GIL锁</h1><ul>
<li>在任何进程中，一次只能有一个线程在执行，因此不能为多线程分配多个CPU，所以python中的线程只能并发，并不能真正的同时运行，也就是不能并行。在python3版本提出的GIL锁的主要作用就是当前线程遇到阻塞的情况下就会切换线程。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 33】解决样本不均衡的方法</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2033%E3%80%91%E8%A7%A3%E5%86%B3%E6%A0%B7%E6%9C%AC%E4%B8%8D%E5%9D%87%E8%A1%A1%E7%9A%84%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>公开数据集在上线前通常都经过了样本均衡处理，因此基于这些数据训练出来的模型表现通常都比较好。但如果是自己在解决实际问题，则经常会遇到样本不均衡，这会导致模型出现过拟合、泛化能力较差的问题，本文就介绍解决样本不均衡的几种方法。</p>
<span id="more"></span>
<h1 id="解决样本不均衡的方法"><a href="#解决样本不均衡的方法" class="headerlink" title="解决样本不均衡的方法"></a>解决样本不均衡的方法</h1><ul>
<li>以多种数据组合形式训练模型并做模型融合。顾名思义，这种方法就是将全部的小样本数据和等量的大样本数据分别组合成几批训练数据集，并以此训练出几个不同的模型并做模型融合，这种方法能够有效的解决样本不均衡问题。</li>
<li>在计算损失函数时改变数据的权重，增加小样本数据的权重，减少大样本的权重。这种方法实际上参考了focal loss的思想，只不过解决的不是难易样本不均衡，而是样本数据量不均衡，同样能保证模型的泛化性能。</li>
<li>过采样小样本，欠采样大样本。也就是对于训练数据，把那些样本量较小的数据多在load数据时重复几遍，对于那些样本量较大的数据，则尽量减少load它们，以此来达到样本均衡的目的。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 30】softmax的概念、作用以及存在的问题</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2030%E3%80%91softmax%E7%9A%84%E6%A6%82%E5%BF%B5%E3%80%81%E4%BD%9C%E7%94%A8%E4%BB%A5%E5%8F%8A%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>softmax是深度学习任务中常用于计算最终输出类别的函数。</p>
<span id="more"></span>
<h1 id="1-softmax概念"><a href="#1-softmax概念" class="headerlink" title="1. softmax概念"></a>1. softmax概念</h1><ul>
<li>softmax和我们普通意义上的max函数不同，每一个元素都有一个概率，而不是其中一个元素为1，其余为0。它的含义是对于输入向量，有多大的概率去选择元素1、元素2、元素3等，主要的目的是使得概率计算过程可导。<h1 id="2-softmax计算公式"><a href="#2-softmax计算公式" class="headerlink" title="2. softmax计算公式"></a>2. softmax计算公式</h1><img src="https://img-blog.csdnimg.cn/0ce640195eb744518ca1c9fc5996e213.png" alt="在这里插入图片描述"><h1 id="3-softmax可能遇到的问题"><a href="#3-softmax可能遇到的问题" class="headerlink" title="3. softmax可能遇到的问题"></a>3. softmax可能遇到的问题</h1></li>
<li>因为softmax函数中存在指数，所以可能会出现上溢和下溢问题，导致最终结果错误但是不会报错，因此使用softmax函数时候一定要考虑该问题，否则后续出问题了是难以定位的。</li>
<li>上溢就是说当softmax的输入值很大时，由于是指数函数，会导致输出过大，从而导致向上溢出。</li>
<li>下溢与之类似，当指数函数接收一个很小的负数作为输入时候，可能会导致输出为0，在后续的使用中可能会出现除0错误，得到NAN结果。</li>
<li>解决方法就是利用softmax的冗余性，让他们全部减去一个值a，a的选取是a=max(x)。<br><img src="https://img-blog.csdnimg.cn/96a485f197a440c9a957287eaea4e06a.png" alt="在这里插入图片描述"></li>
</ul>
<h1 id="4-argmax"><a href="#4-argmax" class="headerlink" title="4. argmax"></a>4. argmax</h1><ul>
<li>当我们通过softmax取得每个元素的概率之后，我们如果想获得最终的类别，需要使用argmax函数获得最大的概率所在的位置，但是该函数是不可导的。输出相当于python中的语句<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">prob_list.index(<span class="built_in">max</span>(prob_list))</span><br></pre></td></tr></table></figure>
<h1 id="5-soft-argmax"><a href="#5-soft-argmax" class="headerlink" title="5. soft-argmax"></a>5. soft-argmax</h1></li>
<li>为了解决argmax函数不可导问题提出了softargmax，最终输出也是最大概率所在的位置，只是这种计算方式是可导的。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 35】python中的深层拷贝和浅层拷贝以及应用场景</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2035%E3%80%91python%E4%B8%AD%E7%9A%84%E6%B7%B1%E5%B1%82%E6%8B%B7%E8%B4%9D%E5%92%8C%E6%B5%85%E5%B1%82%E6%8B%B7%E8%B4%9D%E4%BB%A5%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</url>
    <content><![CDATA[<p>python的深层拷贝和浅层拷贝是一个重要但容易忽视的基础知识，这可能会导致代码出现难以定位的错误。</p>
<span id="more"></span>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><ul>
<li>浅层拷贝。可以理解为c语言中的引用，改变其中一个值，另一个也会跟着改变。</li>
<li>深层拷贝。就是重新生成一个和该变量完全相同的变量，他们值的改变不会相互影响。</li>
<li>在python中，数字、字符、元组等不可变对象类型都属于值传递，即深层拷贝。字典和列表等可变对象都属于引用传递，即浅层拷贝。<h1 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h1></li>
<li>如果想要将当前列表赋值给一个新列表保存中间结果，采用深层拷贝。</li>
<li>如果在dfs等算法中需要多层传递维护一个共用列表，那么可以直接采用浅层拷贝，即直接赋值。</li>
<li>如果在函数中要修改输入的列表，且需要将修改后的结果传回去，那么浅层拷贝可以帮忙节省代码量。</li>
<li>如果在函数中要修改输入的列表，而不想影响外部对应的列表，那么需要采用深层拷贝。<h1 id="深层拷贝和浅层拷贝的示例"><a href="#深层拷贝和浅层拷贝的示例" class="headerlink" title="深层拷贝和浅层拷贝的示例"></a>深层拷贝和浅层拷贝的示例</h1></li>
<li>在这个示例中，直接用<code>=</code>赋值就是浅层拷贝，由于是引用传递，因此<code>a</code>的改变也会导致<code>b</code>的改变。而采用<code>.copy()</code>就是深层拷贝，因此<code>a</code>的改变不会传递给<code>c</code>。<br><img src="https://img-blog.csdnimg.cn/c87b0b418e3d4225bb27bab6f2a23687.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_Q1NETiBA6ZuB5a6HdXA=,size_26,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 36】python生成器、迭代器、修饰器</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2036%E3%80%91python%E7%94%9F%E6%88%90%E5%99%A8%E3%80%81%E8%BF%AD%E4%BB%A3%E5%99%A8%E3%80%81%E4%BF%AE%E9%A5%B0%E5%99%A8/</url>
    <content><![CDATA[<p>python中的生成器、迭代器和修饰器是深度学习框架源码中常用的语法，本文简单介绍一下它们的概念。</p>
<span id="more"></span>
<h1 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h1><ul>
<li>生成器就是定义一个算法或者函数，只不过它的返回值是yield，每次调用next()函数都能计算它下一个元素的值，直到抛出异常。可以理解为程序每次执行到yield的时候都会返回结果并且暂停，再次调用next()函数时就会从上次暂停的地方继续执行。<h1 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h1></li>
<li>生成器就是迭代器的一种，迭代器首先是可以迭代的，也就是实现了iter方法的对象，而迭代器就是既实现了iter方法又实现了next方法。如列表就是python实现的一个迭代器。<h1 id="修饰器"><a href="#修饰器" class="headerlink" title="修饰器"></a>修饰器</h1></li>
<li>修饰器的主要作用就是不改变原先代码的前提下增加额外的功能，也就是去包装另一个函数，更方便的在不对之前代码改动的前提下进行代码复用。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 32】模型涨点的技巧</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2032%E3%80%91%E6%A8%A1%E5%9E%8B%E6%B6%A8%E7%82%B9%E7%9A%84%E6%8A%80%E5%B7%A7/</url>
    <content><![CDATA[<p>大家都希望模型精度越高越好，除了尝试各种不同的模型之外，还可以通过一些训练策略来实现模型的涨点，这里分享一些博主常用的方法。</p>
<span id="more"></span>
<h1 id="1-warm-up"><a href="#1-warm-up" class="headerlink" title="1. warm up"></a>1. warm up</h1><ul>
<li>warm up就是说一开始采用较低的学习率，等训练一段时间之后再采用较高的学习率并且随着学习率衰减策略衰减。能够有效的防止模型在较大学习率的时候由于步长过大很快陷入一个局部最小值区域的问题。<h1 id="2-合适的学习率衰减策略"><a href="#2-合适的学习率衰减策略" class="headerlink" title="2. 合适的学习率衰减策略"></a>2. 合适的学习率衰减策略</h1></li>
<li>学习率衰减策略比较常见，但很多时候大家都是用优化器自带的学习率衰减策略，该策略不一定适合自己的任务。可以自己将学习率、迭代次数、loss、精度曲线画出来，是否在某些学习率下精度仍然有上升趋势，但该趋势还没结束学习率已经进行了衰减，如果有的话那么可以继续增加该段的迭代次数，进而获得更高的模型精度。<h1 id="3-finetuning"><a href="#3-finetuning" class="headerlink" title="3. finetuning"></a>3. finetuning</h1></li>
<li>模型训练结束之后，可以freeze部分layer进行最终的微调，也使得最终模型获得一定程度的涨点。<h1 id="4-单GPU训练"><a href="#4-单GPU训练" class="headerlink" title="4. 单GPU训练"></a>4. 单GPU训练</h1></li>
<li>多卡训练时候由于数据同步问题，比如sync BN就会多多少少带来性能损伤，因此可以尝试单卡训练策略。<h1 id="5-增加数据集"><a href="#5-增加数据集" class="headerlink" title="5. 增加数据集"></a>5. 增加数据集</h1></li>
<li>使用更多更大的数据集也有助于模型涨点 。<h1 id="6-平衡每个batch的数据比例"><a href="#6-平衡每个batch的数据比例" class="headerlink" title="6. 平衡每个batch的数据比例"></a>6. 平衡每个batch的数据比例</h1></li>
<li>如果随机读取数据，那么每个batch并不一定能保证每个类别的数据都包含，因此需要做每个batch的数据均衡。<h1 id="7-采用在公开数据集上训练好的模型作为初始化"><a href="#7-采用在公开数据集上训练好的模型作为初始化" class="headerlink" title="7. 采用在公开数据集上训练好的模型作为初始化"></a>7. 采用在公开数据集上训练好的模型作为初始化</h1></li>
<li>tensorflow、pytorch、paddle等框架都提供了在imagenet等大数据集上训练好的模型，这些模型作为特征提取的backbone通常有更好的模型表征能力，因此采用它们作为初始化效果通常会很好。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 37】解决正负样本不均衡 Focal Loss</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2037%E3%80%91%E8%A7%A3%E5%86%B3%E6%AD%A3%E8%B4%9F%E6%A0%B7%E6%9C%AC%E4%B8%8D%E5%9D%87%E8%A1%A1%20Focal%20Loss/</url>
    <content><![CDATA[<p>正负样本不均衡是检测任务中常见的问题，在目标检测中，大量样本都是不包含目标的负样本，只有少量是包含目标的正样本，而Focal Loss就是为了解决这个问题而提出的。</p>
<span id="more"></span>
<h1 id="Focal-Loss的目的"><a href="#Focal-Loss的目的" class="headerlink" title="Focal Loss的目的"></a>Focal Loss的目的</h1><ul>
<li>focal loss的主要目的是降低易分类样本的权重，使得模型更加关注困难样本，防止大量的简单样本主导模型的优化方向。<h1 id="Focal-Loss的计算方式"><a href="#Focal-Loss的计算方式" class="headerlink" title="Focal Loss的计算方式"></a>Focal Loss的计算方式</h1></li>
<li>解决样本数量不均衡，在交叉熵中给交叉熵一个权重，也就是相反类的比重。这样一来，对于少量的样本，权重就比较大，对于大量的样本，权重就比较小。</li>
<li>解决难易样本不均衡，直观来说，就是对于较难的样本，给一个大权重，对于容易的样本，加一个小权重。具体计算公式如下：<br><img src="https://img-blog.csdnimg.cn/3176959dcf034e8e91dca17caad6ff6f.png" alt="在这里插入图片描述"></li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 40】CNN为什么比DNN在图像领域更具优势</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2040%E3%80%91CNN%E4%B8%BA%E4%BB%80%E4%B9%88%E6%AF%94DNN%E5%9C%A8%E5%9B%BE%E5%83%8F%E9%A2%86%E5%9F%9F%E6%9B%B4%E5%85%B7%E4%BC%98%E5%8A%BF/</url>
    <content><![CDATA[<h1 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h1><ul>
<li>CNN模型输入的一般都是图像矩阵，然后通过卷积操作进行特征提取，每次卷积都会考虑特征的上下文信息，并且随着模型的加深，从浅层提取的局部特征不断地处理、整合得到深层的高维特征。在这个过程中，特征的整合是缓慢有序发生的。同时，卷及操作还具有平移不变形特性，只管来解释就是：一个物体在图像中的任何区域都能被正确识别。因此，CNN在处理图像特征时候更具优势。</li>
<li>DNN的输入时向量形式，并未考虑到图像的结构信息，每一层都会做一个全局的特征提取，但是由于这个过程并非递进的，因此最终的特征质量并不好，因此难以在图像领域发挥出优势。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 38】L1正则化和L2正则化的区别</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2038%E3%80%91L1%E6%AD%A3%E5%88%99%E5%8C%96%E5%92%8CL2%E6%AD%A3%E5%88%99%E5%8C%96%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><ul>
<li>L1正则化就是在损失函数中加的正则化项为模型参数的L1范数。</li>
<li>L2正则化就是在损失函数中加的正则化项为模型参数的L2范数。<span id="more"></span>
<h1 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h1></li>
<li>通过在损失函数中增加权重正则化项，可以避免模型变得过于复杂或者说防止模型的参数过大，从而提升模型的泛化性能。<h1 id="L1正则化和L2正则化的差异"><a href="#L1正则化和L2正则化的差异" class="headerlink" title="L1正则化和L2正则化的差异"></a>L1正则化和L2正则化的差异</h1></li>
<li>加上L1范数容易得到特征的系数解，也就是很多参数为0，加上L2范数得到的特征解比较平滑，但是同样能保证解中接近于0的比较多。从倒数的角度来看，L1范数在零点处有个突变，也就是极小值点，因此很容易优化到这个极值点上。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 42】逻辑回归详解</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2042%E3%80%91%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h1 id="1-概念"><a href="#1-概念" class="headerlink" title="1. 概念"></a>1. 概念</h1><ul>
<li>逻辑（logistic）回归是一个二分类器，函数是sigmoid形式，输出落在0~1之间，输出有概率意义。<span id="more"></span>
<h1 id="2-优点"><a href="#2-优点" class="headerlink" title="2. 优点"></a>2. 优点</h1></li>
<li>输出值自然落在0~1之间，有概率意义。（不能直接当做概率使用，只是一个置信度）</li>
<li>参数代表每个特征对输出的影响，可解释强。<h1 id="3-缺点"><a href="#3-缺点" class="headerlink" title="3. 缺点"></a>3. 缺点</h1></li>
<li>逻辑回归本质上还是线性回归，只是特征到结果的映射过程中增加了一层函数映射，即先把特征线性求和，然后使用sigmoid约束至0~1，结果值可以用于二分类或者回国预测，不可用于多分类问题。</li>
<li>特征空间大时效果不好。</li>
</ul>
<h1 id="4-逻辑回归函数"><a href="#4-逻辑回归函数" class="headerlink" title="4. 逻辑回归函数"></a>4. 逻辑回归函数</h1><p>在说逻辑回归之前要了解优势比的概念：</p>
<h2 id="4-1-优势比"><a href="#4-1-优势比" class="headerlink" title="4.1 优势比"></a>4.1 优势比</h2><ul>
<li>假设在m个独立自变量，x1、x2…xm的作用下，记事件y取1的概率为：<br><img src="https://img-blog.csdnimg.cn/e8019f9b4fd64ecc90380e1ff634bd98.png" alt="在这里插入图片描述"><br>则事件y取0的概率为p = 1 - p，则取1和取0的概率之比为：<br><img src="https://img-blog.csdnimg.cn/f194b8ce950b4c9cb9fe790d3f84bcdb.png" alt="在这里插入图片描述"><br>上式就称为事件的优势比。<h2 id="4-2-logistic函数"><a href="#4-2-logistic函数" class="headerlink" title="4.2 logistic函数"></a>4.2 logistic函数</h2></li>
<li>对优势比期自然对数得到logistic变换：<br><img src="https://img-blog.csdnimg.cn/50c9f561b0ff4398868e9380bec0ff01.png" alt="在这里插入图片描述"><br>令：<br><img src="https://img-blog.csdnimg.cn/1f1653a3b4664e90890a38350b0880dd.png" alt="在这里插入图片描述"><br>则有：<br><img src="https://img-blog.csdnimg.cn/d02c0ed7c1fa4d099b6c8939486de9bd.png" alt="在这里插入图片描述"><br>上式即为logistic函数，也是sigmoid函数，p就是P(y|X)的概率，其中X代表了一系列特征。函数图像如下：<br><img src="https://img-blog.csdnimg.cn/d5e620cd257844b0b8991c0894678341.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6ZuB5a6HdXA=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><h1 id="5-逻辑回归模型"><a href="#5-逻辑回归模型" class="headerlink" title="5. 逻辑回归模型"></a>5. 逻辑回归模型</h1></li>
<li>令上式中的<br><img src="https://img-blog.csdnimg.cn/391c3a4eb4eb4cbf8e64d6894f77af2c.png" alt="在这里插入图片描述"><br>则有：<br><img src="https://img-blog.csdnimg.cn/5a900ae1f06240e4b9a20e9ce65feb5e.png" alt="在这里插入图片描述"><br>实际上计算的就是p(y=1)和1-p(y=0)的优势比，当优势比接近于正无穷时，逻辑回归函数越接近于1，反之当这个优势比越接近于负无穷，那么逻辑回归函数越接近于0。<h1 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h1></li>
<li>逻辑回归本质上还是线性回归，只是特征到结果中加了一层函数映射，即sigmoid函数，先把特征线性求和，然后使用sigmoid函数将线性和约束至（0，1）之间，结果值用于二分类或者回归预测。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 44】逻辑回归实现多分类的方法</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2044%E3%80%91%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%AE%9E%E7%8E%B0%E5%A4%9A%E5%88%86%E7%B1%BB%E7%9A%84%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>方式1</p>
<ul>
<li>在二分类问题上逻辑回归用的激活函数是sigmoid，在多分类的时候可以改为softmax函数。<span id="more"></span></li>
</ul>
<p>方式2</p>
<ul>
<li>根据每一类别都建立一个二分类器，有多少类别就有多少个逻辑回归分类器。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 45】机器学习中常用的距离计算方法</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2045%E3%80%91%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E8%B7%9D%E7%A6%BB%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>假设有两个点(x1, y1) (x2, y2)</p>
<span id="more"></span>
<p>欧氏距离<br><img src="https://img-blog.csdnimg.cn/f580363c526247a1b6b8de7cb9f5b70d.png" alt="在这里插入图片描述"></p>
<p>曼哈顿距离<br><img src="https://img-blog.csdnimg.cn/51f6e836c47f4b81af8c781122a3275d.png" alt="在这里插入图片描述"><br>余弦距离<br><img src="https://img-blog.csdnimg.cn/514aa3122e0e4d7da9713245d968ad4a.png" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 46】贝叶斯定理与条件概率公式</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2046%E3%80%91%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86%E4%B8%8E%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E5%85%AC%E5%BC%8F/</url>
    <content><![CDATA[<h1 id="基本定理"><a href="#基本定理" class="headerlink" title="基本定理"></a>基本定理</h1><ul>
<li>贝叶斯基于概率论中的贝叶斯定理，贝叶斯定理就是用先验概率和条件概率求出最终的事件概率。</li>
<li>贝叶斯网络可以理解为将模型看作是一个概率密度函数，它可以表示数据的分布，训练过程就是概率分布的参数估计过程，预测过程就是求解条件概率的过程。<span id="more"></span>
<h1 id="通过条件概率求得后验概率"><a href="#通过条件概率求得后验概率" class="headerlink" title="通过条件概率求得后验概率"></a>通过条件概率求得后验概率</h1></li>
<li>后验概率可以用条件概率表示，公式为：<br><img src="https://img-blog.csdnimg.cn/e9e8742f5ea1430798d39c111237d3ae.png" alt="在这里插入图片描述"><br>由此可推导：<br><img src="https://img-blog.csdnimg.cn/05f1b3f02cdf483097afeb3095434dd7.png" alt="在这里插入图片描述"><h1 id="从条件概率推导贝叶斯定理"><a href="#从条件概率推导贝叶斯定理" class="headerlink" title="从条件概率推导贝叶斯定理"></a>从条件概率推导贝叶斯定理</h1>见公式<br><img src="https://img-blog.csdnimg.cn/39d894b69661488cbf42c49646c3a84a.png" alt="在这里插入图片描述"></li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 43】优势比的概念</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2043%E3%80%91%E4%BC%98%E5%8A%BF%E6%AF%94%E7%9A%84%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<h1 id="优势比"><a href="#优势比" class="headerlink" title="优势比"></a>优势比</h1><ul>
<li>假设在m个独立自变量，x1、x2…xm的作用下，记事件y取1的概率为：<img src="https://img-blog.csdnimg.cn/e8019f9b4fd64ecc90380e1ff634bd98.png" alt="在这里插入图片描述"><br>则事件y取0的概率为p = 1 - p，则取1和取0的概率之比为：<br><img src="https://img-blog.csdnimg.cn/f194b8ce950b4c9cb9fe790d3f84bcdb.png" alt="在这里插入图片描述"><br>上式就称为事件的优势比。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 39】BN、LN、WN的比较</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2039%E3%80%91BN%E3%80%81LN%E3%80%81WN%E7%9A%84%E6%AF%94%E8%BE%83/</url>
    <content><![CDATA[<h1 id="BN"><a href="#BN" class="headerlink" title="BN"></a>BN</h1><ul>
<li>batch normalization，使之在激活函数接收输入之前将数据的分布规范到标准正态分布中，使得激活函数的输入值落在对输入比较敏感的区域，也就是梯度较大的区域。从而避免梯度消失、减少训练时间。</li>
<li>BN比较适合batch较大的场景，并且数据分布要相对比较接近。<span id="more"></span>
<h1 id="WN"><a href="#WN" class="headerlink" title="WN"></a>WN</h1></li>
<li>weigit normalization，主要就是对网络的权重进行正则化，使得网络不要过于复杂，权重不要过大，可以防止过拟合。<h1 id="LN"><a href="#LN" class="headerlink" title="LN"></a>LN</h1></li>
<li>layer normalization，它相对于BN，不依赖于整个batch，而是针对某一层的输入进行规范化处理，比较适用于小batch、RNN、MLP场景中。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 41】深度学习快速入门学习资料</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2041%E3%80%91%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/</url>
    <content><![CDATA[<p>快开学了，给实验室师弟师妹们推荐一些深度学习快速入门的学习资料：</p>
<span id="more"></span>
<h1 id="书籍"><a href="#书籍" class="headerlink" title="书籍"></a>书籍</h1><ol>
<li>《统计学习方法》- 李航。入门首选书籍，深入浅出，易于理解。</li>
<li>《机器学习实战》，又称蜥蜴书，地位等同于《C++ primer》。可以当字典看。</li>
<li>《机器学习》- 周志华。又称西瓜书，学有余力可以看。</li>
<li>《深度学习》- MIT。又称花书，讲的比较深入，如果想钻研推荐看，也可以当资料查阅。</li>
</ol>
<h1 id="视频资料"><a href="#视频资料" class="headerlink" title="视频资料"></a>视频资料</h1><ol>
<li><a href="https://mooc.study.163.com/smartSpec/detail/1001319001.htm">吴恩达深度学习工程师课程</a>，讲的很容易理解。</li>
<li><a href="https://study.163.com/course/introduction.htm?courseId=1003842018&_trace_c_p_k2_=f024cbcf3fa74db7a1988ccab9eea667">Hinton机器学习与神经网络中文课</a>，神经网络之父的课程。</li>
<li><a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv">李飞飞计算机视觉课程</a>，ImageNet发起人。</li>
<li><a href="https://www.bilibili.com/video/av41393758">CS224n 斯坦福深度自然语言处理课</a>，NLP方向推荐，</li>
</ol>
<h1 id="必备技能"><a href="#必备技能" class="headerlink" title="必备技能"></a>必备技能</h1><p>想要做好深度学习，python、Linux是必备技能，numpy、tensorflow、pytorch、paddle库也都是必须熟悉的，Git可以帮助提高代码开发效率。菜鸟教程的内容十分推荐花时间看一遍。</p>
<ol>
<li><a href="https://www.runoob.com/python3/python3-tutorial.html">python3 菜鸟教程</a></li>
<li><a href="https://www.runoob.com/linux/linux-tutorial.html">Linux 菜鸟教程</a></li>
<li><a href="https://docs.python.org/zh-cn/3/library/index.html">python 标准库</a></li>
<li><a href="https://numpy.org/doc/stable/reference/">numpy API</a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf">tensorflow API</a></li>
<li><a href="https://tensorflow.google.cn/api_docs/python/tf">pytorch API</a></li>
<li><a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/index_cn.html">paddle API</a></li>
<li><a href="https://www.runoob.com/git/git-tutorial.html">Git 菜鸟教程</a></li>
</ol>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 47】贝叶斯网络与朴素贝叶斯</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2047%E3%80%91%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</url>
    <content><![CDATA[<p>朴素贝叶斯要求特征彼此独立，且对被解释的变量影响一致、不能进行变量筛选，即特征之间不能存在依赖关系，且不能给每个特征加权重，通常这种条件是难以满足的。为了解决这个问题，就出现了贝叶斯网络。下表展示了两者之间的对比。</p>
<span id="more"></span>

<table>
<thead>
<tr>
<th>对比维度</th>
<th>贝叶斯网络</th>
<th>朴素贝叶斯</th>
</tr>
</thead>
<tbody><tr>
<td>假设前提</td>
<td>1.各变量都是离散型的<br>2.各特征间有依赖关系<br>3.没一个节点在其前驱节点的值制定后，这个节点条件独立于其所有非直接前驱结点<br>4.贝叶斯网络放宽了每个独立变量的假设</td>
<td>1.各特征之间彼此独立<br>2.对于若干条件概率值不存在的问题，一般通过将所有的概率值加1来解决<br>3.对被解释的变量影响一致，不能进行变量筛选</td>
</tr>
<tr>
<td>应用案例</td>
<td>1.在信息不完备的情况下通过观察随机变量推断不可观察的随机变量<br>2.解决文本分类中相邻词的关系、近义词的关系</td>
<td>分类</td>
</tr>
<tr>
<td>优点</td>
<td>1.贝叶斯原理和图论相结合，能建立一种基于概率推理的可解释的数学模型，对于解决复杂的不确定性和关联性问题有很强的优势<br>2.对缺失数据不敏感<br>3.可以学习因果关系，加深对数据的理解<br>4.能将先验知识融入建模<br>5.一定程度上避免了过拟合问题</td>
<td>思想简单直观，对于给出的待分类箱，会选择条件概率最大的类别</td>
</tr>
<tr>
<td>缺点</td>
<td>彼此之间不独立的特征会加大模型复杂性。</td>
<td>不能进行变量筛选。</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 48】贝叶斯网络的特点</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2048%E3%80%91%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C%E7%9A%84%E7%89%B9%E7%82%B9/</url>
    <content><![CDATA[<h1 id="贝叶斯网络的特点"><a href="#贝叶斯网络的特点" class="headerlink" title="贝叶斯网络的特点"></a>贝叶斯网络的特点</h1><ul>
<li>贝叶斯网络主要引入了两个基本概念：有向无环图和条件概率集合。<span id="more"></span></li>
<li>有向无环图的节点是特征和类别，边是两个特征或者特征和类别之间的关系，并不是彼此独立的。</li>
<li>条件概率集合主要的概念是条件独立性，也就是某个节点在给定其父节点的条件下，与其他节点是相互独立的。</li>
<li>贝叶斯网络关注的不是因果关系，而是变量间的依赖关系。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习目标检测系列 - 02】目标检测的常见算法</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%B3%BB%E5%88%97%20-%2002%E3%80%91%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>目标检测(Object Detection)一直以来都是深度学习领域的热门话题，这个系列的文章会对其进行详细的梳理。</p>
<span id="more"></span>
<h1 id="1-传统的检测算法"><a href="#1-传统的检测算法" class="headerlink" title="1. 传统的检测算法"></a>1. 传统的检测算法</h1><ul>
<li>Cascade + HOG/DPM + Haar/SVM以及上述方法的诸多改进、优化</li>
</ul>
<h1 id="2-候选区域-深度学习分类："><a href="#2-候选区域-深度学习分类：" class="headerlink" title="2. 候选区域+深度学习分类："></a>2. 候选区域+深度学习分类：</h1><p>提取候选区域，对相应的区域进行以深度学习方法为主的分类。</p>
<ul>
<li>R-CNN</li>
<li>SPP-NET</li>
<li>Fast R-CNN</li>
<li>Faster R-CNN</li>
</ul>
<h1 id="3-基于深度学习的回归方法，YOLO-SSD-DenseBox"><a href="#3-基于深度学习的回归方法，YOLO-SSD-DenseBox" class="headerlink" title="3. 基于深度学习的回归方法，YOLO/SSD/DenseBox"></a>3. 基于深度学习的回归方法，YOLO/SSD/DenseBox</h1><p>看下图</p>
<p>![[目标检测的常见算法.jpg]]</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习目标检测系列 - 01】目标检测是什么</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%B3%BB%E5%88%97%20-%2001%E3%80%91%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%98%AF%E4%BB%80%E4%B9%88/</url>
    <content><![CDATA[<p>目标检测(Object Detection)一直以来都是深度学习领域的热门话题，这个系列的文章会对其进行详细的梳理。</p>
<span id="more"></span>
<h1 id="1-目标检测是什么"><a href="#1-目标检测是什么" class="headerlink" title="1. 目标检测是什么"></a>1. 目标检测是什么</h1><ul>
<li>图像分类任务回答的是”图像中的物体是什么”。而目标检测任务回答的是”图像中的物体是什么，它处于图像的什么位置”。</li>
<li>即，不但要输出目标所属的类别，还要输出物体的位置信息。位置信息通常采用bounding box表示，也就是给定一个矩形框的中心坐标以及宽高信息来定位框在图像中所属的位置。</li>
</ul>
<h1 id="2-如何进行目标检测"><a href="#2-如何进行目标检测" class="headerlink" title="2. 如何进行目标检测"></a>2. 如何进行目标检测</h1><ul>
<li>从流程上进行分类一般有两种，即two-stage的方法和ont-shot的方法。</li>
<li>two-stage的方法，也就是先产生候选区域，然后对每个候选区域进行分类，再通过回归来修正bounding box，最后通过非极大值抑制来确定最终的检测结果。</li>
<li>one-shot方法的主要代表就是YOLO系列，它的思想是先将图片划分成一个个的单元格，然后对每个单元格进行处理，直接预测出当前位置是否存在物体、bounding box的位置以及分类的概率。</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 49】Kmeans</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2049%E3%80%91Kmeans/</url>
    <content><![CDATA[<p>Kmeans是一个原理较为简单的聚类模型，它的操作步骤是</p>
<ol>
<li>随机选择k个点作为初始类心。</li>
<li>计算每个元素和k个类心之间的距离并归类到最近的类里面。</li>
<li>以每个类的均值作为新的类心。</li>
<li>重复2和3知道所有的类心不再变化。</li>
</ol>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 50】PCA降维 主成成分分析</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2050%E3%80%91PCA%E9%99%8D%E7%BB%B4%20%E4%B8%BB%E6%88%90%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="PCA降维的原理"><a href="#PCA降维的原理" class="headerlink" title="PCA降维的原理"></a>PCA降维的原理</h1><ul>
<li>PCA可以把可能具有相关性的高维变量合成线性无关的低维变量，称为主成分（ principal components）。新的低维数据集会尽可能的保留原始数据的变量。</li>
<li>降维方式就是通过分析数据的主成分，在不丢失过多信息的情况下，通过映射将高维数据投影到较低纬度的数据中去。<span id="more"></span></li>
</ul>
<h1 id="主成分的计算"><a href="#主成分的计算" class="headerlink" title="主成分的计算"></a>主成分的计算</h1><ul>
<li>矩阵的主成分是由其协方差矩阵的特征向量，按照对应的特征值大小排序得到的。最大的特征值就是第一主成分，第二大的特征值就是第二主成分，以此类推。</li>
</ul>
<h1 id="方差与协方差"><a href="#方差与协方差" class="headerlink" title="方差与协方差"></a>方差与协方差</h1><ul>
<li><strong>方差</strong>：用于度量一组数据的离散程度，是各个样本和样本均值差的平方的均值。公式如下：<br>$$ s^2=\frac {\sum^n_{i=1}(X_i-\overline X)} {n-1} $$</li>
<li><strong>协方差</strong>：度量两个变量线性相关性的程度。如果协方差为零，则意味着二者线性无关（并非完全独立，只是没有线性相关性）协方差大于零意味着一个变量增大另一个也增大，即正相关。协方差小于零意味着一个变量增大另一个变量减小，即负相关。<br>$$ conv(X,Y) = \frac {\sum^n_{i=1}(X_i-\overline X)(Y_i - \overline Y)} {n-1} $$</li>
<li><strong>协方差矩阵</strong>：由数据集中两两变量的协方差组成。矩阵中第$(i，j)$个元素就是数据集中第$i$和第$j$个元素的协方差。</li>
</ul>
<h1 id="特征向量与特征值"><a href="#特征向量与特征值" class="headerlink" title="特征向量与特征值"></a>特征向量与特征值</h1><ul>
<li>特征向量就相当于坐标轴，特征值就相当于坐标。</li>
<li>特征向量就是由满足如下矩阵得到的非零向量：<br>$$ A\vec v = \lambda\vec v $$</li>
<li>其中$A$是矩阵， $\vec v$是特征向量，$\lambda$是特征值。</li>
</ul>
<h1 id="PCA降维的作用"><a href="#PCA降维的作用" class="headerlink" title="PCA降维的作用"></a>PCA降维的作用</h1><p>降维致力于解决三类问题。</p>
<ol>
<li>降维可以缓解维度灾难问题；</li>
<li>降维可以在压缩数据的同时让信息损失最小化；</li>
<li>理解几百个维度的数据结构很困难，两三个维度的数据通过可视化更容易理解。</li>
</ol>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【深度学习基础知识 - 51】推荐算法概述</title>
    <url>/2022/01/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20-%2051%E3%80%91%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<p>以前在网上查找资料需要进入网站之后分门别类的点进去，在一个个子类别下找到自己想要的东西，这是用户人工查找的过程。到后来的谷歌百度，可以直接搜索自己想要的内容，搜索网站就会把和你搜索目标相匹配的内容展示出来。</p>
<span id="more"></span>

<p>但是在某些情况下，如在找想看的电影时，用户并不知道自己想要看的电影具体是什么，这个时候推荐算法就派上用场了。</p>
<hr>
<p>在任何情况下都不能无中生有给用户推荐内容，常见的参照为：</p>
<ol>
<li> 根据和该用户有共同喜好的人来推荐。</li>
<li> 根据你喜欢的物品找出相似的来推荐</li>
<li> 根据你给出的关键字来推荐，不过这类似于搜索算法。</li>
<li> 根据上面几种条件的组合来推荐。</li>
</ol>
<p>常见的推荐算法：</p>
<ol>
<li> 基于流行度的推荐算法：主要是堆热点商品或信息的推荐</li>
<li> 基于内容的推荐算法：它的主要思想是根据推荐物品或内容的元数据，发现与其相关的内容或物品。比如看过哈利波特1，就会推荐哈利波特2等。这种方法易于实现。</li>
<li> 基于关联规则的推荐算法，具体意义为：购买了一些物品的用户更倾向于买另一些物品。这是由于两者之间存在某些关联，而这些相关的内容都可以相互推荐。</li>
<li> 基于协同过滤的推荐算法：喜欢相同物品的用于可能有相同的兴趣，可以细分为基于用户据的推荐和基于物品的推荐。</li>
<li> 基于模型的推荐算法：主要是使用机器学习算法对目标用户建立推荐算法模型，然后对预测的结果进行打分，当然其中也需要一些人为干预，这会使得模型的结果更好。</li>
<li> 混合推荐算法：实际应用中单一的推荐算法难以满足推荐任务的需求，所以更多情况下可能需要结合多种推荐算法来实现推荐任务，即多种推荐算法的融合。</li>
</ol>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【视频编解码 - 01】标准-codec之间的关系</title>
    <url>/2022/01/13/%E3%80%90%E8%A7%86%E9%A2%91%E7%BC%96%E8%A7%A3%E7%A0%81%20-%2001%E3%80%91%E6%A0%87%E5%87%86-codec%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB/</url>
    <content><![CDATA[<p>一开始接触视频编解码的时候一直没有搞明白常说的AVC/H.264、HEVC/H.265等视频编码标准和常说的x264之间有什么联系，后来请教了组内大佬搞明白了，在这里记录下。</p>
<span id="more"></span>

<h1 id="视频编码标准"><a href="#视频编码标准" class="headerlink" title="视频编码标准"></a>视频编码标准</h1><p>视频编码标准一般是标准指定组织收到各种各样的提案之后，经过开会讨论、审计之后决定上线的一系列工具的总和。当这些标准出现之后，离真正落地使用还是有一段距离的，因此就出现了各种编解码器（codec）。</p>
<h1 id="codec"><a href="#codec" class="headerlink" title="codec"></a>codec</h1><p>有了标准之后，需要根据这些标准实现一些可用的编解码器，这些编解码器又称codec。各个企业的工作中，通常会根据一些开源的codec方法去依据自己任务中的编码复杂度、时间消耗以及效果的trad-off来具体去进行优化和配置。这也是视频算法工程师的主要工作内容。</p>
]]></content>
      <categories>
        <category>视频编码</category>
      </categories>
      <tags>
        <tag>视频编码</tag>
      </tags>
  </entry>
  <entry>
    <title>【视频编解码 - 02】视频编码名词解释</title>
    <url>/2022/01/13/%E3%80%90%E8%A7%86%E9%A2%91%E7%BC%96%E8%A7%A3%E7%A0%81%20-%2002%E3%80%91%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/</url>
    <content><![CDATA[<p>这篇文章一起学习一下视频编码中的常见名词。</p>
<span id="more"></span>
<table>
<thead>
<tr>
<th>分类</th>
<th>术语</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>基础术语</td>
<td>编码和视频编码</td>
<td>编码就是按指定的方法，将信息从一种形式(格式)，转换成另一种形式(格式)的技术。视频编码是指运用数据压缩技术将数字视频信号中的冗余信息去除，将原始视频格式的文件转换成另一种视频格式文件，以降低表示原始视频所需的码率，方便视频数据的传输与存储的一种技术。</td>
</tr>
<tr>
<td>基础术语</td>
<td>视频编解码器</td>
<td>是指一个能够对数字视频进行压缩或者解压缩的程序或者设备。通常这种压缩属于有损数据压缩，即压缩前和压缩后的视频数据并不完全一致，但是一般人眼觉察不到这种差别。</td>
</tr>
<tr>
<td>基础术语</td>
<td>视频预处理</td>
<td>为了去除视频采集过程中可能存在一些瑕疵或者出于利于视频编码的目的在编码前进行的处理， 通常的视频处理包含视频去噪，视频锐化，色彩/亮度/对比度增强等。</td>
</tr>
<tr>
<td>基础术语</td>
<td>混合视频编码框架</td>
<td>混合编码（Hybrid Coding）框架是目前广泛使用的视频编码框架，混合编码框架是指将预测编码，变换编码等多个类型的编码方法应用在同一个框架内的编码方法，流程主要分为预测、变换、量化、熵编码四个步骤，其中预测主要分为帧内预测和帧间预测。</td>
</tr>
<tr>
<td>标准与实现</td>
<td>标准与实现的关系</td>
<td>标准：视频编码标准是指定组织收到各种各样的提案之后，经过开会讨论、审计之后决定上线的一系列工具的总和。但是这些标准离真正使用还有一定距离，因此就出现了各种各样的实现方式。实现：有了标准之后，要根据这些标准实现一些具体可用的编解码器，如x264/x265。在企业的具体工作中，通常会在些开源实现的基础上进一步针对自己的业务进行优化。</td>
</tr>
<tr>
<td>标准与实现</td>
<td>AVC/H.264</td>
<td>H.264，同时也是MPEG-4第十部分，是由ITU-T视频编码专家组（VCEG）和ISO/IEC动态图像专家组（MPEG）联合组成的联合视频组（JVT，Joint Video Team）提出的一种面向块的基于运动补偿的高度压缩数字视频的编解码器标准。这个标准通常被称之为H.264/AVC（或者AVC/H.264或者H.264/MPEG-4 AVC或MPEG-4/H.264 AVC）而明确的说明它两方面的开发者。</td>
</tr>
<tr>
<td>标准与实现</td>
<td>HEVC/H.265</td>
<td>高效率视频编码（High Efficiency Video Coding，简称HEVC），又称为H.265和MPEG-H第2部分，是一种视频压缩标准，被视为是ITU-T H.264/MPEG-4 AVC标准的继任者。2004年开始由ISO/IEC Moving Picture Experts Group（MPEG）和ITU-T Video Coding Experts Group（VCEG）作为ISO/IEC 23008-2 MPEG-H Part 2或称作ITU-T H.265开始制定。第一版的HEVC/H.265视频压缩标准在2013年4月13日被接受为国际电信联盟（ITU-T）的正式标准。HEVC被认为不仅提升影像质量，同时也能达到H.264/MPEG-4 AVC两倍之压缩率（等同于同样画面质量下比特率减少到了50%），可支持4K清晰度甚至到超高清电视（UHDTV），最高清晰度可达到8192×4320（8K清晰度）。</td>
</tr>
<tr>
<td>标准与实现</td>
<td>VVC/H.266</td>
<td>多功能视频编码（Versatile Video Coding，简称VVC），也称为H.266、MPEG-I第3部分或未来视频编码（FVC），是由联合视频专家组（JVET），于2020年7月6日最终确定的视频压缩标准。它是高效视频编码 （HEVC，也称为ITU-T H.265和MPEG-H第2部分）的后继标准。</td>
</tr>
<tr>
<td>标准与实现</td>
<td>JM/x264</td>
<td>JM和x264都是AVC/H.264视频编码标准的一种具体实现。JM：JM通常被认为是H.264标准制定团队所认可的官方参考软件，基本实现了AVC/H.264标准的全部特征。JM在运行时的运算过程较为复杂，而且没有采用汇编优化等加速方法，因此运行速度较慢，很难达到实时编解码。通常主要用于编解码技术的科学研究领域。x264：x264是著名的H.264开源视频编码器，由开源组织VideoLan开发制定。X264是目前企业界应用最为广泛的开源编码器，主要因为X264相对于JM进行了大量的优化与简化，使其运行效率大幅提高，主要有对编码代价计算方法的简化以及添加了MMX、SSE汇编优化等部分。虽然编码的质量在某些情况下相对于JM略有下降，但是已无法掩盖其在可应用性，尤其是实时编码方面无可比拟的优势。</td>
</tr>
<tr>
<td>标准与实现</td>
<td>HM/x265</td>
<td>HM和x265都是HEVC/H.265视频编码标准的一种具体实现。HM：HM是HEVC/H.265标准制定团队JCT-VC小组维护的参考软件，基本实现了HEVC的全部特征。HM主要以实现HEVC/H.266标准为目的，相关的速度优化比较少，运行速度比较慢，通常用于给相关研究者提供一个统一的研究和评测平台。x265：x265是一个用于编码符合高效率视频编码（HEVC/H.265）标准的视频的开源自由软件及函数库。与x264项目类似，x265使用GNU通用公共许可证（GPL）2授权或商业许可证授权提供。x265相较于HM也进行的大量的优化，增加汇编优化和多种快速算法，虽然编码的质量在某些情况下相较于HM有些下降，但是运行效率大幅度的提高，在实时编码方面展现了巨大的优势。</td>
</tr>
<tr>
<td>标准与实现</td>
<td>VTM/VVenC</td>
<td>VTM和VVenC都是VVC/H.266视频编码标准的一种具体实现。VTM：VTM是由MPEG和VCEG联合建立的JVET小组在JVET第10次圣地亚哥会议上，第一次并发布的VVC/H.266测试模型。VTM主要以实现VVC/H.266标准为目的，相关的速度优化比较少，编码速度比较慢，主要是为研究者提供一个统一的研究和评测平台。VVenC：VVenC主要是为了解决VTM运行速度慢而在VTM的基础上，重新设计软件以减轻性能瓶颈，实现了广泛的SIMD优化，改进的编码器搜索算法以及基本的多线程支持等产生的一个很好地兼顾编码性能与编码速度的VVC/H.266标准实现。</td>
</tr>
<tr>
<td>码率控制</td>
<td>编码帧类型</td>
<td>在视频编码序列中，主要有三种编码帧：I帧、P帧、B帧; I 帧（Intra Coded Picture）：又称帧内编码帧，为关键帧，是一种自带全部信息的独立帧，无需参考其他图像便可独立进行解码，可以简单理解为一张静态画面。视频序列中的第一个帧始终都是I 帧，每个 GOP 由I 帧开始。P 帧（Predictive Coded Picture）：又称帧间预测编码帧，需要参考前面的I帧才能进行编码。表示的是当前帧画面与前一帧（前一帧可能是I帧也可能是P帧）的差别。解码时需要用之前缓存的画面叠加上本帧定义的差别，生成最终画面。与I帧相比，P帧通常占用更少的数据位，但不足是，由于P帧对前面的P和I参考帧有着复杂的依赖性，因此对传输错误非常敏感。B 帧（Bidirectionally Predictive Coded Pictures）：又称双向预测编码帧，也就是B帧记录的是本帧与前后帧的差别。也就是说要解码B帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的与本帧数据的叠加取得最终的画面。B帧压缩率高，但是对解码性能要求较高。</td>
</tr>
<tr>
<td>码率控制</td>
<td>GOP</td>
<td>GOP值表示关键帧的间隔（即两个关键帧之间的帧数），也就是两个IDR帧之间的距离，一个帧组的最大帧数。一般包括由一个 I-帧和若干个 P-帧和 B-帧组成的连续帧序列</td>
</tr>
<tr>
<td>码率控制</td>
<td>宏块</td>
<td>宏块是编码处理的基本单元，通常宏块大小为16x16个像素。一个编码图像首先要划分成多个块（4x4 像素）才能进行处理，显然宏块应该由整数个块组成。宏块分为I、P、B宏块：I宏块（帧内预测宏块）只能利用当前片中已解码的像素作为参考进行帧内预测；P宏块（帧间预测宏块）可以利用前面已解码的图像作为参考图像进行帧内预测；B宏块（帧间双向预测宏块）则是利用前后向的参考图像进行帧内预测。</td>
</tr>
<tr>
<td>码率控制</td>
<td>码率控制</td>
<td>视频编码是一个有损编码的过程，其目的是在尽量保持视频质量的的同时尽可能多的节省比特（码率）。码率控制就是平衡码率和质量的重要工具。根据不同的应用场景，需要选择不同的码率控制算法，包括”1-pass”,”2-pass”,”CBR”,”VBR”,”VBV Encoding”和”CRF”。</td>
</tr>
<tr>
<td>码率控制</td>
<td><strong>固定量化参数</strong>(Constant QP, CQP)</td>
<td>最简单的码率控制方式，每帧图像都按照一个特定的QP来编码，每帧编码后的数据量有多大是未知的，既不是码率优先模型也不是质量优先模型，不过是实现最简单的模型。一般不建议使用这种方式，因为这种方式不考虑编码内容的复杂性，用相同的压缩比处理每一帧。出来的视频质量和码率都不固定。具有编码速度快，调控最简单,每帧的QP值相同，但是瞬时码率会随场景复杂度波动的特点。</td>
</tr>
<tr>
<td>码率控制</td>
<td><strong>恒定码率系数</strong>(Constant Rate Factor, CRF）</td>
<td>把某一个”视觉质量”作为输出目标。通过降低那些耗费码率但是又难以用肉眼察觉的帧（高速运动或者纹理丰富）的质量提升那些静态帧的码率来达到此目的。由于帧间QP变化，帧内宏块的QP变化，输出码率未知，但是各帧输出的视觉质量基本恒定，适用于对视频质量有一定要求的场合</td>
</tr>
<tr>
<td>码率控制</td>
<td><strong>恒定码率</strong> <strong>(Constant Bit Rate, CBR)</strong></td>
<td>一定时间范围内比特率基本保持的恒定，属于码率优先模型。具有码率稳定，但是质量不稳定，带宽有效利用率不高，但是输出视频码率基本稳定，便于计算视频体积大小的特点。但是特别当该值设置不合理，在复杂运动场景下，画面非常模糊，非常影响观看体验。</td>
</tr>
<tr>
<td>码率控制</td>
<td>可变码率(Variable Bit Rate, <strong>VBR)</strong></td>
<td>简单场景分配比较大的QP，压缩率小，质量高。复杂场景分配较小QP。得到基本稳定的视觉质量，因为人眼人眼本来就对复杂场景不敏感，缺点在于输出码率大小不可控。</td>
</tr>
<tr>
<td>码率控制</td>
<td>二次编码方式(2PASS)</td>
<td>第一次编码检测视频内容的简单和复杂部分，同时确定简单和复杂的比例。第二遍编码会让视频的平均码率不变，复杂的地方分配多bit,简单地方分配少bit。具有码率不稳定，质量基本稳定且非常高；编码速度一般比较慢的特点。在点播、下载和存储系统可以优先使用，不适合低延时、直播系统。</td>
</tr>
<tr>
<td>码率控制</td>
<td>平均比特率(Average Bitrate, ABR)</td>
<td>简单场景分配较低bit,复杂场景分配足够bit，使得有限的bit数能够在不同场景下合理分配，这类似VBR。同时一定时间内，平均码率又接近设置的目标码率，这样可以控制输出文件的大小，这又类似CBR。可以认为是CBR和VBR的折中方案，这是大多人的选择。特别在对质量和视频带宽都有要求的情况下，可以优先选择该模式，一般速度是VBR的两倍到三倍，相同体积的视频文件质量却比CBR好很多。具有视频质量整体可控，同时兼顾了视频码率和速度的优点，是一个折中方案，在直播和低延时系统中用的比较多。在使用过程一般要配合最低码率、最高码率和平均码率综合使用。</td>
</tr>
<tr>
<td>量化</td>
<td>量化</td>
<td>量化是指将信号的连续取值(或大量可能的离散取值)映射为有限多个离散值的过程，实现信号取值多对一的映射。在视频/图像编码中，残差信号经过DCT后，变换系数往往具有较大的动态范围，因此对变换系数进行量化可以有效地减小信号取值空间，获得更好的压缩效果。量化分为两类，如下：标量量化：无需分析数据统计特性，复杂度低，但平均量化误差大。被主流的图像、视频编码标准所采用；矢量量化：基于数据统计属性的量化器，平均量化误差低，但不容易实现。</td>
</tr>
<tr>
<td>量化</td>
<td>量化参数</td>
<td>量化参数（QP）是量化过程中选取的将连续的取值离散化的阈值，它反映了空间细节压缩情况，如QP小，大部分的细节都会被保留；QP增大，一些细节丢失，码率降低，但图像失真加强和质量下降。也就是说，QP和比特率成反比的关系，而且随着视频源复杂度的提高，这种反比关系会更明显。码率控制的核心就是确定宏块的QP。码率控制是一级一级进行控制的，先分配图像组级（GOP）的比特数，然后分配图像级的比特数，再分配CTU级别的比特数。利用已经分配的比特数来确定量化参数。通过对比已经分配的比特数和时间编码产生的比特数差异对码控参数进行更新。</td>
</tr>
<tr>
<td>量化</td>
<td>自适应量化</td>
<td>自适应量化就是根据宏块的复杂度来调整每个宏块量化时的量化参数。x264中有3中自适应量化模式可供选择：1）基于方差的自适应量化，2）基于自协方差的自适应量化，3）基于带偏置的自协方差自适应量化</td>
</tr>
<tr>
<td>量化</td>
<td>MBTree</td>
<td>在x264中，mb-tree是默认开启的，和自适应量化一起控制MB级的QP。mb-tree的具体作用原理是根据该MB在帧间预测中贡献给未来帧（在编码顺序里位于当前帧之后的帧）的信息，即被参考的情况，来调整该宏块的QP值。简言之，如果该MB贡献给后续帧的信息越多，则其重要性越高，应当提高该区域的编码质量，减少QP，反之，则增大该区域的QP。</td>
</tr>
<tr>
<td>深度学习</td>
<td>注意力机制</td>
<td>人类对信息的感知和理解的过程并非遵循严格的解码规范，而是会根据注意力对信息进行筛选，机器的注意力机制就是对这一过程的仿生，即处理信息时根据每段信息的重要性对其进行筛选。</td>
</tr>
<tr>
<td>深度学习</td>
<td>自注意力机制</td>
<td>通过让信息进行自我关联，找出信息内部的关系权重，进而指导深度学习模型对信息价值的判断和选择。</td>
</tr>
<tr>
<td>深度学习</td>
<td>视觉全自注意力网络</td>
<td>视觉全自注意力网络（Vision Transformer）是一种基于自注意力机制，通过深度神经网络进行训练的深度学习模型。</td>
</tr>
<tr>
<td>深度学习</td>
<td>残差网络</td>
<td>残差网络（ResNet）是一种基于深度学习的卷积神经网络，在本文档中主要用于图像内容复杂度的计算。</td>
</tr>
<tr>
<td>深度学习</td>
<td>图像序列化</td>
<td>序列化（Embedding）是将离散的变量转换为对应连续向量的过程。图像的序列化是将二维图像映射为一维向量的过程。</td>
</tr>
<tr>
<td>深度学习</td>
<td>感知机</td>
<td>是一个基于神经网络的判别模型，主要用于二分类任务。</td>
</tr>
<tr>
<td>评价指标</td>
<td>SSIM</td>
<td>图像结构相似性（Structural Similarity）是一种计算两张图像之间结构相似性的方法，在视频编码中主要用于评估视频编码中每一张图像压缩之后的质量。</td>
</tr>
<tr>
<td>评价指标</td>
<td>PSNR</td>
<td>峰值信噪比（Peak Signal to Noise Ratio）即峰值信号的能量与噪声之间的平均能量之比，是视频编码中用于评估每一张图像编码质量的常用的客观指标。</td>
</tr>
<tr>
<td>评价指标</td>
<td>VMAF</td>
<td>VMAF (Video Multimethod Assessment Fusion) 由 Netflix 开发并开源，利用大量的主观数据作为训练集，通过机器学习的手段将不同评估维度的算法进行“融合”，得到一个能准确反映主观意志的画质评价标准。VMAF 主要包括3种指标：visual quality fidelity（VIF）、detail loss measure（DLM）、temporal information（TI）。其中 VIF 和 DLM 是空间域的也即一帧画面之内的特征，TI 是时间域的也即多帧画面之间相关性的特征。这些特性之间融合计算总分的过程使用了训练好的 SVM 来预测。</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>视频编码</category>
      </categories>
      <tags>
        <tag>视频编码</tag>
      </tags>
  </entry>
  <entry>
    <title>【通过算法题学习python技巧 - 02】剑指 Offer 04. 二维数组中的查找</title>
    <url>/2022/01/13/%E3%80%90%E9%80%9A%E8%BF%87%E7%AE%97%E6%B3%95%E9%A2%98%E5%AD%A6%E4%B9%A0python%E6%8A%80%E5%B7%A7%20-%2002%E3%80%91%E5%89%91%E6%8C%87%20Offer%2004.%20%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E6%9F%A5%E6%89%BE/</url>
    <content><![CDATA[<p>本专栏的目的是通过算法题学习python技巧，并非实现算法题的最优解。</p>
<span id="more"></span>


<h1 id="剑指-Offer-04-二维数组中的查找"><a href="#剑指-Offer-04-二维数组中的查找" class="headerlink" title="剑指 Offer 04. 二维数组中的查找"></a>剑指 Offer 04. 二维数组中的查找</h1><p><a href="https://leetcode-cn.com/problems/er-wei-shu-zu-zhong-de-cha-zhao-lcof/">题目链接</a></p>
<blockquote>
<p>在一个 n * m 的二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个高效的函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。</p>
<p>示例:</p>
<p>现有矩阵 matrix 如下：</p>
<p>[[1,   4,  7, 11, 15],<br>  [2,   5,  8, 12, 19],<br>  [3,   6,  9, 16, 22],<br>  [10, 13, 14, 17, 24],<br>  [18, 21, 23, 26, 30]]<br>给定 target = 5，返回 true。</p>
<p>给定 target = 20，返回 false。</p>
</blockquote>
<p>本题最优解是二维二分查找，或者将二维变成一维再用二分查找。但是在这里我们尝试一下用<code>in</code>来解决。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findNumberIn2DArray</span>(<span class="params">self, matrix: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]], target: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        number_in_array = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> matrix:</span><br><span class="line">            number_in_array = number_in_array <span class="keyword">or</span> target <span class="keyword">in</span> line</span><br><span class="line">            <span class="keyword">if</span> number_in_array:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> number_in_array</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>【通过算法题学习python技巧 - 03】剑指 Offer 05. 替换空格</title>
    <url>/2022/01/13/%E3%80%90%E9%80%9A%E8%BF%87%E7%AE%97%E6%B3%95%E9%A2%98%E5%AD%A6%E4%B9%A0python%E6%8A%80%E5%B7%A7%20-%2003%E3%80%91%E5%89%91%E6%8C%87%20Offer%2005.%20%E6%9B%BF%E6%8D%A2%E7%A9%BA%E6%A0%BC/</url>
    <content><![CDATA[<p>本专栏的目的是通过算法题学习python技巧，并非实现算法题的最优解。</p>
<span id="more"></span>


<h1 id="剑指-Offer-05-替换空格"><a href="#剑指-Offer-05-替换空格" class="headerlink" title="剑指 Offer 05. 替换空格"></a>剑指 Offer 05. 替换空格</h1><p><a href="https://leetcode-cn.com/problems/ti-huan-kong-ge-lcof/">题目链接</a></p>
<blockquote>
<p>请实现一个函数，把字符串 s 中的每个空格替换成”%20”。</p>
<p> </p>
<p>示例 1：</p>
<p>输入：s = “We are happy.”<br>输出：”We%20are%20happy.”</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">replaceSpace</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">        <span class="keyword">return</span> s.replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;%20&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>【通过算法题学习python技巧 - 04】剑指 Offer 06. 从尾到头打印链表</title>
    <url>/2022/01/13/%E3%80%90%E9%80%9A%E8%BF%87%E7%AE%97%E6%B3%95%E9%A2%98%E5%AD%A6%E4%B9%A0python%E6%8A%80%E5%B7%A7%20-%2004%E3%80%91%E5%89%91%E6%8C%87%20Offer%2006.%20%E4%BB%8E%E5%B0%BE%E5%88%B0%E5%A4%B4%E6%89%93%E5%8D%B0%E9%93%BE%E8%A1%A8/</url>
    <content><![CDATA[<p>本专栏的目的是通过算法题学习python技巧，并非实现算法题的最优解。</p>
<span id="more"></span>


<h1 id="剑指-Offer-06-从尾到头打印链表"><a href="#剑指-Offer-06-从尾到头打印链表" class="headerlink" title="剑指 Offer 06. 从尾到头打印链表"></a>剑指 Offer 06. 从尾到头打印链表</h1><p><a href="https://leetcode-cn.com/problems/cong-wei-dao-tou-da-yin-lian-biao-lcof/">题目链接</a></p>
<blockquote>
<p>输入一个链表的头节点，从尾到头反过来返回每个节点的值（用数组返回）。</p>
<p>示例 1：</p>
<p>输入：head = [1,3,2]<br>输出：[2,3,1]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reversePrint</span>(<span class="params">self, head: ListNode</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">while</span> head:</span><br><span class="line">            res.append(head.val)</span><br><span class="line">            head = head.<span class="built_in">next</span></span><br><span class="line">        res.reverse()</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>【通过算法题学习python技巧 - 01】剑指offer 03. 数组中重复的数字</title>
    <url>/2022/01/13/%E3%80%90%E9%80%9A%E8%BF%87%E7%AE%97%E6%B3%95%E9%A2%98%E5%AD%A6%E4%B9%A0python%E6%8A%80%E5%B7%A7%20-%2001%E3%80%91%E5%89%91%E6%8C%87offer%2003.%20%E6%95%B0%E7%BB%84%E4%B8%AD%E9%87%8D%E5%A4%8D%E7%9A%84%E6%95%B0%E5%AD%97/</url>
    <content><![CDATA[<p>本专栏的目的是通过算法题学习python技巧，并非实现算法题的最优解。</p>
<span id="more"></span>


<h1 id="剑指offer-03-数组中重复的数字"><a href="#剑指offer-03-数组中重复的数字" class="headerlink" title="剑指offer 03. 数组中重复的数字"></a>剑指offer 03. 数组中重复的数字</h1><p><a href="https://leetcode-cn.com/problems/shu-zu-zhong-zhong-fu-de-shu-zi-lcof/">题目链接</a></p>
<blockquote>
<p>找出数组中重复的数字。</p>
<p>在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。</p>
<p>示例 1：</p>
<p>输入：<br>[2, 3, 1, 0, 2, 5, 3]<br>输出：2 或 3 </p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findRepeatNumber</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Counter会返回一个dict，key是字符，val是字符出现的次数</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line">        count = Counter(nums)</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> count.items():</span><br><span class="line">            <span class="keyword">if</span> v &gt; <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> k</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>【通过算法题学习python技巧 - 06】剑指 Offer 15. 二进制中1的个数</title>
    <url>/2022/01/13/%E3%80%90%E9%80%9A%E8%BF%87%E7%AE%97%E6%B3%95%E9%A2%98%E5%AD%A6%E4%B9%A0python%E6%8A%80%E5%B7%A7%20-%2006%E3%80%91%E5%89%91%E6%8C%87%20Offer%2015.%20%E4%BA%8C%E8%BF%9B%E5%88%B6%E4%B8%AD1%E7%9A%84%E4%B8%AA%E6%95%B0/</url>
    <content><![CDATA[<p>本专栏的目的是通过算法题学习python技巧，并非实现算法题的最优解。</p>
<span id="more"></span>


<h1 id="剑指-Offer-15-二进制中1的个数"><a href="#剑指-Offer-15-二进制中1的个数" class="headerlink" title="剑指 Offer 15. 二进制中1的个数"></a>剑指 Offer 15. 二进制中1的个数</h1><p><a href="https://leetcode-cn.com/problems/er-jin-zhi-zhong-1de-ge-shu-lcof/">题目链接</a></p>
<blockquote>
<p>编写一个函数，输入是一个无符号整数（以二进制串的形式），返回其二进制表达式中数字位数为 ‘1’ 的个数（也被称为 汉明重量).）。</p>
<p>提示：</p>
<p>请注意，在某些语言（如 Java）中，没有无符号整数类型。在这种情况下，输入和输出都将被指定为有符号整数类型，并且不应影响您的实现，因为无论整数是有符号的还是无符号的，其内部的二进制表示形式都是相同的。<br>在 Java 中，编译器使用 二进制补码 记法来表示有符号整数。因此，在上面的 示例 3 中，输入表示有符号整数 -3。
 </p>
<p>示例 1：</p>
<p>输入：n = 11 (控制台输入 00000000000000000000000000001011)<br>输出：3<br>解释：输入的二进制串 00000000000000000000000000001011 中，共有三位为 ‘1’。</p>
</blockquote>
<p>直接用<code>bin</code>和<code>count</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hammingWeight</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">bin</span>(n).count(<span class="string">&#x27;1&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>【通过算法题学习python技巧 - 05】剑指 Offer 10- I. 斐波那契数列</title>
    <url>/2022/01/13/%E3%80%90%E9%80%9A%E8%BF%87%E7%AE%97%E6%B3%95%E9%A2%98%E5%AD%A6%E4%B9%A0python%E6%8A%80%E5%B7%A7%20-%2005%E3%80%91%E5%89%91%E6%8C%87%20Offer%2010-%20I.%20%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0%E5%88%97/</url>
    <content><![CDATA[<p>本专栏的目的是通过算法题学习python技巧，并非实现算法题的最优解。</p>
<span id="more"></span>


<h1 id="剑指-Offer-10-I-斐波那契数列"><a href="#剑指-Offer-10-I-斐波那契数列" class="headerlink" title="剑指 Offer 10- I. 斐波那契数列"></a>剑指 Offer 10- I. 斐波那契数列</h1><p><a href="https://leetcode-cn.com/problems/fei-bo-na-qi-shu-lie-lcof/">题目链接</a></p>
<blockquote>
<p>写一个函数，输入 n ，求斐波那契（Fibonacci）数列的第 n 项（即 F(N)）。斐波那契数列的定义如下：</p>
<p>F(0) = 0,   F(1) = 1<br>F(N) = F(N - 1) + F(N - 2), 其中 N &gt; 1.<br>斐波那契数列由 0 和 1 开始，之后的斐波那契数就是由之前的两数相加而得出。</p>
<p>答案需要取模 1e9+7（1000000007），如计算初始结果为：1000000008，请返回 1。</p>
<p> </p>
<p>示例 1：</p>
<p>输入：n = 2<br>输出：1<br>示例 2：</p>
<p>输入：n = 5<br>输出：5</p>
</blockquote>
<p>生成器版的菲波那切数列是最简洁的写法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fib</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        res = self.m_fib(n)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span>):</span><br><span class="line">            <span class="built_in">next</span>(res)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">next</span>(res)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">m_fib</span>(<span class="params">self, n</span>):</span></span><br><span class="line">        a = b = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">yield</span> a</span><br><span class="line">            a, b = b, a + b</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>【通过算法题学习python技巧 - 09】剑指 Offer 20. 表示数值的字符串</title>
    <url>/2022/01/13/%E3%80%90%E9%80%9A%E8%BF%87%E7%AE%97%E6%B3%95%E9%A2%98%E5%AD%A6%E4%B9%A0python%E6%8A%80%E5%B7%A7%20-%2009%E3%80%91%E5%89%91%E6%8C%87%20Offer%2020.%20%E8%A1%A8%E7%A4%BA%E6%95%B0%E5%80%BC%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2/</url>
    <content><![CDATA[<p>本专栏的目的是通过算法题学习python技巧，并非实现算法题的最优解。</p>
<span id="more"></span>


<h1 id="剑指-Offer-20-表示数值的字符串"><a href="#剑指-Offer-20-表示数值的字符串" class="headerlink" title="剑指 Offer 20. 表示数值的字符串"></a>剑指 Offer 20. 表示数值的字符串</h1><p><a href="https://leetcode-cn.com/problems/biao-shi-shu-zhi-de-zi-fu-chuan-lcof/">题目链接</a></p>
<blockquote>
<p>请实现一个函数用来判断字符串是否表示数值（包括整数和小数）。</p>
<p>数值（按顺序）可以分成以下几个部分：</p>
<p>若干空格<br>一个 小数 或者 整数<br>（可选）一个 ‘e’ 或 ‘E’ ，后面跟着一个 整数<br>若干空格<br>小数（按顺序）可以分成以下几个部分：</p>
<p>（可选）一个符号字符（’+’ 或 ‘-‘）<br>下述格式之一：<br>至少一位数字，后面跟着一个点 ‘.’<br>至少一位数字，后面跟着一个点 ‘.’ ，后面再跟着至少一位数字<br>一个点 ‘.’ ，后面跟着至少一位数字<br>整数（按顺序）可以分成以下几个部分：</p>
<p>（可选）一个符号字符（’+’ 或 ‘-‘）<br>至少一位数字<br>部分数值列举如下：</p>
<p>[“+100”, “5e2”, “-123”, “3.1416”, “-1E-16”, “0123”]<br>部分非数值列举如下：</p>
<p>[“12e”, “1a3.14”, “1.2.3”, “+-5”, “12e+5.4”]
 </p>
<p>示例 1：</p>
<p>输入：s = “0”<br>输出：true<br>示例 2：</p>
<p>输入：s = “e”<br>输出：false</p>
</blockquote>
<p>python可以直接实现字符串和数字的转换</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isNumber</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="built_in">float</span>(s)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>【通过算法题学习python技巧 - 08】剑指 Offer 19. 正则表达式匹配</title>
    <url>/2022/01/13/%E3%80%90%E9%80%9A%E8%BF%87%E7%AE%97%E6%B3%95%E9%A2%98%E5%AD%A6%E4%B9%A0python%E6%8A%80%E5%B7%A7%20-%2008%E3%80%91%E5%89%91%E6%8C%87%20Offer%2019.%20%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%8C%B9%E9%85%8D/</url>
    <content><![CDATA[<p>本专栏的目的是通过算法题学习python技巧，并非实现算法题的最优解。</p>
<span id="more"></span>


<h1 id="剑指-Offer-19-正则表达式匹配"><a href="#剑指-Offer-19-正则表达式匹配" class="headerlink" title="剑指 Offer 19. 正则表达式匹配"></a>剑指 Offer 19. 正则表达式匹配</h1><p><a href="https://leetcode-cn.com/problems/zheng-ze-biao-da-shi-pi-pei-lcof/">题目链接</a></p>
<blockquote>
<p>请实现一个函数用来匹配包含’. ‘和’<em>‘的正则表达式。模式中的字符’.’表示任意一个字符，而’</em>‘表示它前面的字符可以出现任意次（含0次）。在本题中，匹配是指字符串的所有字符匹配整个模式。例如，字符串”aaa”与模式”a.a”和”ab<em>ac</em>a”匹配，但与”aa.a”和”ab*a”均不匹配。</p>
<p>示例 1:</p>
<p>输入:<br>s = “aa”<br>p = “a”<br>输出: false<br>解释: “a” 无法匹配 “aa” 整个字符串。<br>示例 2:</p>
<p>输入:<br>s = “aa”<br>p = “a*”<br>输出: true<br>解释: 因为 ‘*’ 代表可以匹配零个或多个前面的那一个元素, 在这里前面的元素就是 ‘a’。因此，字符串 “aa” 可被视为 ‘a’ 重复了一次。</p>
</blockquote>
<p><code>re</code>库是最好的正则表达式库。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isMatch</span>(<span class="params">self, s: <span class="built_in">str</span>, p: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="keyword">import</span> re</span><br><span class="line">        search_res = re.<span class="built_in">compile</span>(p).search(s)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> search_res:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> s == re.<span class="built_in">compile</span>(p).search(s).group()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>【通过算法题学习python技巧 - 11】剑指 Offer 39. 数组中出现次数超过一半的数字</title>
    <url>/2022/01/13/%E3%80%90%E9%80%9A%E8%BF%87%E7%AE%97%E6%B3%95%E9%A2%98%E5%AD%A6%E4%B9%A0python%E6%8A%80%E5%B7%A7%20-%2011%E3%80%91%E5%89%91%E6%8C%87%20Offer%2039.%20%E6%95%B0%E7%BB%84%E4%B8%AD%E5%87%BA%E7%8E%B0%E6%AC%A1%E6%95%B0%E8%B6%85%E8%BF%87%E4%B8%80%E5%8D%8A%E7%9A%84%E6%95%B0%E5%AD%97/</url>
    <content><![CDATA[<p>本专栏的目的是通过算法题学习python技巧，并非实现算法题的最优解。</p>
<span id="more"></span>


<h1 id="剑指-Offer-39-数组中出现次数超过一半的数字"><a href="#剑指-Offer-39-数组中出现次数超过一半的数字" class="headerlink" title="剑指 Offer 39. 数组中出现次数超过一半的数字"></a>剑指 Offer 39. 数组中出现次数超过一半的数字</h1><p><a href="https://leetcode-cn.com/problems/shu-zu-zhong-chu-xian-ci-shu-chao-guo-yi-ban-de-shu-zi-lcof/">题目链接</a></p>
<blockquote>
<p>数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。</p>
<p>你可以假设数组是非空的，并且给定的数组总是存在多数元素。
 </p>
<p>示例 1:</p>
<p>输入: [1, 2, 3, 2, 2, 2, 5, 4, 2]<br>输出: 2</p>
</blockquote>
<p>collections 是一个经常能用到的包。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">majorityElement</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> Counter(nums).items():</span><br><span class="line">            <span class="keyword">if</span> v &gt;= <span class="built_in">len</span>(nums) / <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">return</span> k</span><br><span class="line">        <span class="keyword">return</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>一个优质的软件开发流程必备要素</title>
    <url>/2022/01/13/%E5%B7%A5%E4%BD%9C%E5%BF%83%E5%BE%97%20-%20%E4%B8%80%E4%B8%AA%E4%BC%98%E8%B4%A8%E7%9A%84%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B%E5%BF%85%E5%A4%87%E8%A6%81%E7%B4%A0/</url>
    <content><![CDATA[<h1 id="codereview"><a href="#codereview" class="headerlink" title="codereview"></a>codereview</h1><ul>
<li>在日常工作中想必大家都经历过codereview，这是一个艰苦卓绝、费心费时费力的工作，但确实如此的必要。有许多因素导致在各个企业中codereview的地位如此重要，其中最关键的就是防止破窗效应、保持项目组代码风格统一。这两者都是为了以后的协作开发提高工作效率而服务的。</li>
<li>防止破窗效应可以让大家有主人翁意识，尽量避免因为一个人写的烂而导致大家一起写的烂。</li>
<li>保持项目组代码风格统一可以提升新人和相互之间读代码的效率，让整个项目好像出自一个人之手。<span id="more"></span></li>
</ul>
<h1 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h1><ul>
<li>相信从事软件开发工作的人们对单元测试都非常熟悉了，以单元测试驱动的编程过程有助于你将代码解耦，首先编写单元测试可以让你明确代码的接口、降低耦合程度、将它们变成一个个独立的模块，后续可以大幅降低工作量。</li>
<li>相比之下，算法工程师的日常工作中可能对单元测试接触的比较少，但是也推荐大家去以单元测试的思路去编程，一样可以提高代码可读性，受益匪浅。</li>
</ul>
<h1 id="写文档、检查语法"><a href="#写文档、检查语法" class="headerlink" title="写文档、检查语法"></a>写文档、检查语法</h1><ul>
<li>可以用pylint等工具检查语法。</li>
<li>给每个函数写注释，然后用api自己生成代码文档。注释中可以包含输入、输出、示例等。这都有助于提高后期的工作效率。</li>
<li>业务文档。</li>
</ul>
<h1 id="多人协作开发流程"><a href="#多人协作开发流程" class="headerlink" title="多人协作开发流程"></a>多人协作开发流程</h1><ol>
<li>首先，想清楚需求。需求的提出者不一定明白自己想要什么，你们需要一遍遍的讨论去明确或者帮助需求方去明确他们想要的东西。</li>
<li>设计单元测试，单元测试的作用是给实现这个需求进行模块的划分，想清楚自己的每个模块完成什么功能、提供什么接口。</li>
<li>动手写代码，这是最简单的一步。不过要时刻谨记写出高可读的代码。可以参考我的<a href="https://blog.csdn.net/yanyuxiangtoday/article/details/119767148?spm=1001.2014.3001.5501">《编写可读代码的艺术》读书笔记</a>。</li>
<li>写完之后要接入自动化测试流程，让别人的每次commit都会自动的进行单元测试，保证其他人的提交无害，保证多人协作代码的兼容。（如果你们还没有自动化测试流程，那为什么你不动手做呢？）</li>
<li>自动集成自动发布（CICD）。</li>
</ol>
]]></content>
      <categories>
        <category>工作心得</category>
      </categories>
      <tags>
        <tag>CodeReview</tag>
        <tag>CICD</tag>
      </tags>
  </entry>
  <entry>
    <title>【通过算法题学习python技巧 - 10】剑指 Offer 21. 调整数组顺序使奇数位于偶数前面</title>
    <url>/2022/01/13/%E3%80%90%E9%80%9A%E8%BF%87%E7%AE%97%E6%B3%95%E9%A2%98%E5%AD%A6%E4%B9%A0python%E6%8A%80%E5%B7%A7%20-%2010%E3%80%91%E5%89%91%E6%8C%87%20Offer%2021.%20%E8%B0%83%E6%95%B4%E6%95%B0%E7%BB%84%E9%A1%BA%E5%BA%8F%E4%BD%BF%E5%A5%87%E6%95%B0%E4%BD%8D%E4%BA%8E%E5%81%B6%E6%95%B0%E5%89%8D%E9%9D%A2/</url>
    <content><![CDATA[<p>本专栏的目的是通过算法题学习python技巧，并非实现算法题的最优解。</p>
<span id="more"></span>


<h1 id="剑指-Offer-21-调整数组顺序使奇数位于偶数前面"><a href="#剑指-Offer-21-调整数组顺序使奇数位于偶数前面" class="headerlink" title="剑指 Offer 21. 调整数组顺序使奇数位于偶数前面"></a>剑指 Offer 21. 调整数组顺序使奇数位于偶数前面</h1><p><a href="https://leetcode-cn.com/problems/diao-zheng-shu-zu-shun-xu-shi-qi-shu-wei-yu-ou-shu-qian-mian-lcof/">题目链接</a></p>
<blockquote>
<p>输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有奇数位于数组的前半部分，所有偶数位于数组的后半部分。</p>
<p> </p>
<p>示例：</p>
<p>输入：nums = [1,2,3,4]<br>输出：[1,3,2,4]<br>注：[3,1,2,4] 也是正确的答案之一。</p>
</blockquote>
<p>列表递推表达式一行写完是不是很酷。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">exchange</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        <span class="keyword">return</span> [num <span class="keyword">for</span> num <span class="keyword">in</span> nums <span class="keyword">if</span> num % <span class="number">2</span> == <span class="number">1</span>] + [num <span class="keyword">for</span> num <span class="keyword">in</span> nums <span class="keyword">if</span> num % <span class="number">2</span> == <span class="number">0</span>]</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>【通过算法题学习python技巧 - 07】剑指 Offer 17. 打印从1到最大的n位数</title>
    <url>/2022/01/13/%E3%80%90%E9%80%9A%E8%BF%87%E7%AE%97%E6%B3%95%E9%A2%98%E5%AD%A6%E4%B9%A0python%E6%8A%80%E5%B7%A7%20-%2007%E3%80%91%E5%89%91%E6%8C%87%20Offer%2017.%20%E6%89%93%E5%8D%B0%E4%BB%8E1%E5%88%B0%E6%9C%80%E5%A4%A7%E7%9A%84n%E4%BD%8D%E6%95%B0/</url>
    <content><![CDATA[<p>本专栏的目的是通过算法题学习python技巧，并非实现算法题的最优解。</p>
<span id="more"></span>


<h1 id="剑指-Offer-17-打印从1到最大的n位数"><a href="#剑指-Offer-17-打印从1到最大的n位数" class="headerlink" title="剑指 Offer 17. 打印从1到最大的n位数"></a>剑指 Offer 17. 打印从1到最大的n位数</h1><p><a href="https://leetcode-cn.com/problems/da-yin-cong-1dao-zui-da-de-nwei-shu-lcof/">题目链接</a></p>
<blockquote>
<p>输入数字 n，按顺序打印出从 1 到最大的 n 位十进制数。比如输入 3，则打印出 1、2、3 一直到最大的 3 位数 999。</p>
<p>示例 1:</p>
<p>输入: n = 1<br>输出: [1,2,3,4,5,6,7,8,9]</p>
</blockquote>
<p>善用<code>range</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">printNumbers</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>**n))</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>cmakelists 写法</title>
    <url>/2022/01/13/%E6%97%A5%E7%A7%AF%E7%A1%85%E6%AD%A5%20-%20cmakelists%20%E5%86%99%E6%B3%95/</url>
    <content><![CDATA[<p>在某个项目的开发工作中需要用同事的代码，但是由于某些原因没有cmakelist，于是在学习过程中将一些内容记录下来。</p>
<span id="more"></span>

<p>对于一个包（要加入include，然后加入libpath）</p>
<ul>
<li>  首先要include_directories(/path/to/include)</li>
<li>set(libXXX_path /path/to/lib)<ul>
<li>  这一步的目的是将/path/to/lib赋值给libXXX_path，之后可以通过${libXXX_path}调用</li>
</ul>
</li>
<li>  add_executable(project_name main.cpp)</li>
<li>  target_link_libraries(${PROJECT_NAME} ${libXXX_path})</li>
</ul>
<p>file(GLOB opencvLibs /usr/local/Cellar/opencv/4.5.2/lib/libopencv_*.4.5.2.dylib)</p>
<ul>
<li>  含义是将 /usr/local/Cellar/opencv/4.5.2/lib/libopencv_*.4.5.2.dylib 赋值给opencvLibs，同时它是一个全局通配符，这样就不用一个个去查找包了</li>
</ul>
<p>设置执行文件输出路径</p>
<ul>
<li>  SET(EXECUTABLE_OUTPUT_PATH path/to/dump/）</li>
</ul>
<p>库的命名规则是</p>
<ul>
<li>  libXXX（也就是库xxx）</li>
</ul>
]]></content>
      <categories>
        <category>日积硅步</category>
      </categories>
      <tags>
        <tag>skill</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>root 手机</title>
    <url>/2022/01/13/%E6%97%A5%E7%A7%AF%E7%A1%85%E6%AD%A5%20-%20root%E6%89%8B%E6%9C%BA/</url>
    <content><![CDATA[<p>在Android开发的一个任务重需要root手机来检测手机的GPU使用情况，记录一下root手机方法，只需要两个命令。<br>首先，在命令行中启动adb shell，然后执行：</p>
<span id="more"></span>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ adb root</span><br><span class="line">$ adb remount</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>日积硅步</category>
      </categories>
      <tags>
        <tag>skill</tag>
        <tag>adb</tag>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title>工程优化三板斧</title>
    <url>/2022/01/13/%E5%B7%A5%E7%A8%8B%E4%BC%98%E5%8C%96%20-%20%E5%B7%A5%E7%A8%8B%E4%BC%98%E5%8C%96%E4%B8%89%E6%9D%BF%E6%96%A7/</url>
    <content><![CDATA[<h1 id="优化“哲学”的例子"><a href="#优化“哲学”的例子" class="headerlink" title="优化“哲学”的例子"></a>优化“哲学”的例子</h1><ul>
<li>优化最怕跳转，<code>for if等</code></li>
<li>如一个<code>if else</code>结构，大概率为真的放前面。<span id="more"></span></li>
</ul>
<h1 id="优化三板斧"><a href="#优化三板斧" class="headerlink" title="优化三板斧"></a>优化三板斧</h1><ul>
<li>人多力量大<ul>
<li>SIMD（单指令多数据流）</li>
<li>多核多线程</li>
<li>GPU、FPGA</li>
</ul>
</li>
<li>空间换时间<ul>
<li>胸有成竹（查表）</li>
<li>粘贴复制（循环展开、inline）</li>
</ul>
</li>
<li>乾坤大挪移（不改变算法逻辑，只改变排列方式）<ul>
<li>物以类聚</li>
<li>化整为零</li>
<li>一心一意</li>
</ul>
</li>
</ul>
<h1 id="人多力量大"><a href="#人多力量大" class="headerlink" title="人多力量大"></a>人多力量大</h1><ul>
<li>SIMD（单指令多数据流）<ul>
<li>细粒度的并行计算，并行度是确定的</li>
<li>效率提升幅度与寄存器的位宽成正比关系</li>
<li>优化要点是提高计算密度</li>
</ul>
</li>
<li>多核多线程<ul>
<li>粗颗粒度的并行计算，并行度有波动</li>
<li>效率提升幅度与CPU核数和任务的划分分配方式有关</li>
<li>优化要点是任务分配要碎片话，平均化</li>
</ul>
</li>
</ul>
<h1 id="SIMD小技巧"><a href="#SIMD小技巧" class="headerlink" title="SIMD小技巧"></a>SIMD小技巧</h1><ul>
<li>矩阵转置很有用<ul>
<li>应用在IDCT和SATD以及滤波器计算等</li>
</ul>
</li>
<li>遇到判断该怎么办<ul>
<li>真假各计算一遍，有一定开销，但是可以并行<ul>
<li>计算判断为真的结果<code>-&gt;_T</code></li>
<li>计算判断为假的结果<code>-&gt;_F</code></li>
<li>判断结果<code>-&gt;_M</code></li>
<li><code>_R = _T&amp;_M</code></li>
<li><code>_R| = _F&amp;(~_M)</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="多核多线程"><a href="#多核多线程" class="headerlink" title="多核多线程"></a>多核多线程</h1><ul>
<li>多线程并行计算</li>
<li>减少等待时间</li>
</ul>
<h1 id="空间换时间"><a href="#空间换时间" class="headerlink" title="空间换时间"></a>空间换时间</h1><ul>
<li>查表<ul>
<li>查表就是计算过程的固化</li>
<li>优点：速度快</li>
<li>缺点：因空间限制，自变量的范围有限（自变量如果是int，那么表就需要4GB，但是16位的short，只需要64KB）</li>
</ul>
</li>
<li>循环或者inline函数展开<ul>
<li>大多数硬件平台，跳转会打断指令执行流水线，造成延时</li>
<li>适用范围：循环次数固定且比较少，循环内指令量也比较少</li>
<li>需要测试比较，因循环跳转造成的延时多，还是展开后代码量增大造成读取指令缓存不中比较多</li>
</ul>
</li>
<li>查表小技巧<ul>
<li>NEON指令集查表指令(<code>t, tbl</code>指令，并行查表)：<code>int8x8_t vtbl1_s8(init8x8_t__a, int8x8_t__b)</code></li>
</ul>
</li>
</ul>
<h1 id="乾坤大挪移"><a href="#乾坤大挪移" class="headerlink" title="乾坤大挪移"></a>乾坤大挪移</h1><ul>
<li>不改变算法逻辑，只改变代码的排列方式</li>
<li>如<code>for</code>循环纵向取数改为横向取数</li>
</ul>
<h2 id="物以类聚"><a href="#物以类聚" class="headerlink" title="物以类聚"></a>物以类聚</h2><ul>
<li>一次DDR内存boost读写需要最少10cycle</li>
<li>chache以line为基本单元组织起来，每个line映射一组内存</li>
<li>长度是有限的，一般是64byge</li>
<li>为了提高cache使用效率，最好把一次计算时用到的所有数据摆放到一起，或者若干连续计算所需数据连续摆放<h2 id="化整为零"><a href="#化整为零" class="headerlink" title="化整为零"></a>化整为零</h2></li>
<li>cache容量有限，先入先出，在处理大量数据时，后面的数据会将前方数据顶出cache</li>
<li>大量数据如需多次计算，应该分段分块处理以提高cache效率<h2 id="一心一意"><a href="#一心一意" class="headerlink" title="一心一意"></a>一心一意</h2></li>
<li>大量数据经过分割后，分块数据应该集中做完所有计算，以提高cache效率</li>
<li>如一个filter处理二维图像<ul>
<li>可以先多线程各做一行</li>
<li>然后多线程做纵向的一块</li>
<li>进一步优化：</li>
</ul>
</li>
</ul>
<h1 id="练好内功"><a href="#练好内功" class="headerlink" title="练好内功"></a>练好内功</h1><ul>
<li>熟悉硬件（CPU, memory, cache, 指令集, DMA···）</li>
<li>熟悉汇编和编译</li>
<li>熟悉算法</li>
<li>反汇编，看看指令是否能合并，看看是否哪里可以优化，看看最底层的东西，比如取数据，操作流程？</li>
<li>学习过程：去学习别人优化的比较好的代码。比如<code>ffmpeg</code>，想想他们为什么要这样写</li>
</ul>
]]></content>
      <categories>
        <category>工程优化</category>
      </categories>
      <tags>
        <tag>SIMD</tag>
        <tag>工程优化</tag>
        <tag>推理加速</tag>
        <tag>汇编</tag>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title>查看cuda和cudnn版本</title>
    <url>/2022/01/13/%E6%97%A5%E7%A7%AF%E7%A1%85%E6%AD%A5%20-%20%E6%9F%A5%E7%9C%8Bcuda%E5%92%8Ccudnn%E7%89%88%E6%9C%AC/</url>
    <content><![CDATA[<p>cuda版本</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat /usr/<span class="built_in">local</span>/cuda/version.txt</span></span><br></pre></td></tr></table></figure>
<span id="more"></span>

<p>cudnn版本</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat /usr/<span class="built_in">local</span>/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>日积硅步</category>
      </categories>
      <tags>
        <tag>cuda</tag>
      </tags>
  </entry>
  <entry>
    <title>yum update 与 upgrade 的区别</title>
    <url>/2022/01/13/%E6%97%A5%E7%A7%AF%E7%A1%85%E6%AD%A5%20-%20yum%20update%E5%92%8Cupgrade%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p>在日常开发工作中，根据不同的项目会需要配置环境和包，有时候会由于版本问题出现错误，这个时候通常就需要执行<code>update</code>或者<code>upgrade</code>命令，这里简要介绍一下区别。</p>
<span id="more"></span>

<p><code>yum -y update</code>命令升级所有包的同时也会升级软件和系统内核。<br><code>yum -y upgrade</code>命令只升级所有包，不升级软件和系统内核。</p>
<p>通常我们采用<code>yum -y upgrade</code>命令即可。</p>
]]></content>
      <categories>
        <category>日积硅步</category>
      </categories>
      <tags>
        <tag>skill</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title>多cuda版本切换</title>
    <url>/2022/01/13/%E6%97%A5%E7%A7%AF%E7%A1%85%E6%AD%A5%20-%20%E5%A4%9Acuda%E7%89%88%E6%9C%AC%E5%88%87%E6%8D%A2/</url>
    <content><![CDATA[<p>日常开发中经常会需要多个cuda版本共存，本文介绍一下切换cuda版本的方法。</p>
<span id="more"></span>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 删除之前的软连接</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> rm /usr/<span class="built_in">local</span>/cuda</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建新的软连接</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo ln -s /usr/<span class="built_in">local</span>/cuda-11.0 /usr/<span class="built_in">local</span>/cuda</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看当前cuda版本</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> nvcc --version</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>日积硅步</category>
      </categories>
      <tags>
        <tag>cuda</tag>
      </tags>
  </entry>
  <entry>
    <title>《编写可读代码的艺术》 - 写出优雅的代码</title>
    <url>/2022/01/13/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%20-%20%E3%80%8A%E7%BC%96%E5%86%99%E5%8F%AF%E8%AF%BB%E4%BB%A3%E7%A0%81%E7%9A%84%E8%89%BA%E6%9C%AF%E3%80%8B%20-%20%E5%86%99%E5%87%BA%E4%BC%98%E9%9B%85%E7%9A%84%E4%BB%A3%E7%A0%81/</url>
    <content><![CDATA[<p>​​最近看了《编写可读代码的艺术》收获颇丰，刚好这本书的读书笔记适合放在这里。程序员的一大乐趣就是可以自己决定创作出的东西，而代码的可读性、代码是否优雅，都决定了你作品的好坏，想要好的作品吗？那就想办法写出更优美的代码吧。</p>
<span id="more"></span>

<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>程序员之间的互相尊重和对工作的尊重都体现在代码中。</p>
<p>代码是写给人读的，应该便于理解，优质的代码可以让协作变得高效。</p>
<p>学习编写好代码的习惯，并应用于实践中。</p>
<h1 id="第1章-代码应该易于理解"><a href="#第1章-代码应该易于理解" class="headerlink" title="第1章 代码应该易于理解"></a><strong>第1章 代码应该易于理解</strong></h1><ul>
<li>  代码的写法应该使别人理解它所需的时间最小化。</li>
<li>  要多想一想当前在写的代码别人是否容易理解它。</li>
</ul>
<h1 id="第一部分-表面层次的改进"><a href="#第一部分-表面层次的改进" class="headerlink" title="第一部分 表面层次的改进"></a><strong>第一部分 表面层次的改进</strong></h1><ul>
<li>  代码风格</li>
<li>  命名</li>
<li>  排版</li>
<li>注释</li>
</ul>
<h2 id="第2章-把信息装到名字里"><a href="#第2章-把信息装到名字里" class="headerlink" title="第2章 把信息装到名字里"></a><strong>第2章 把信息装到名字里</strong></h2><ul>
<li>  选择专业的词。</li>
<li>  避免泛泛的名字。</li>
<li>  用具体的名字代替抽象的名字。</li>
<li>使用前缀或者后缀附加更多信息。<ul>
<li>  增加单位。如time_cost_day, time_cost_ms</li>
<li>  当前数据格式。如i_days，f_days。</li>
<li>  未处理的变量前面加raw_等</li>
</ul>
</li>
<li>控制名字长度的依据<ul>
<li>  如果变量作用域小，则可以使用较短的名字。如果变量作用域较大，则尽量使用信息完备的名字。</li>
<li>  采用缩写的原则是：团队新成员能否理解这个命名</li>
</ul>
</li>
<li>利用名字的格式来表达含义<ul>
<li>  可参考Google C++代码风格</li>
<li>  类名、函数名首单词大写</li>
<li>  宏全大写</li>
<li>  变量名全小写，用下划线隔开</li>
<li>  成员变量最后可以加下划线等，如CountChars_</li>
</ul>
</li>
<li>如果一个flag要用于多个模式选择，那么就拆分flag，给他们不同的命名。</li>
</ul>
<h2 id="第3章-不会误解的名字"><a href="#第3章-不会误解的名字" class="headerlink" title="第3章 不会误解的名字"></a><strong>第3章 不会误解的名字</strong></h2><ul>
<li>  多问自己几遍，这个名字会被别人解读为其他含义吗？</li>
<li>  命名尽量具体</li>
<li>  用min、max表示包含的极限</li>
<li>  用first和last表示闭区间（stop表示右开，last是右闭）</li>
<li>  用begin和end表示左闭右开区间</li>
<li>给布尔值命名<ul>
<li>  bool read_password = true，不能确定是需要读密码还是已经读取了密码</li>
<li>  bool need_password = true会更好。</li>
<li>  通常加上is、has、can、should这样的词可以让布尔值更加明确。</li>
</ul>
</li>
<li>命名需要与使用者的期望相匹配<ul>
<li>  如GetMean（），可能是直接获取已经计算好的mean，也可能是循环计算mean。改成ComputeMean会更好。</li>
<li>  如调用size（）可以改为CountSize（）。</li>
</ul>
</li>
</ul>
<h2 id="第4章-审美"><a href="#第4章-审美" class="headerlink" title="第4章 审美"></a><strong>第4章 审美</strong></h2><ul>
<li>  保持自己风格一致</li>
<li>  让相似的代码看上去相似</li>
<li>  把相关的代码行分组，形成代码块</li>
<li>  列对齐：整洁易读，容易发现错误。</li>
<li>选择一个有意义的顺序，始终一致的使用它。如：<ul>
<li>  从最重要，到最不重要排序。</li>
<li>  按字母顺序排序</li>
</ul>
</li>
<li>用空行把代码分成逻辑上的段落<ul>
<li>  相似的想法放在一起并且与其他想法分开</li>
<li>  提供可见的注释脚印</li>
<li>  便于段落间导航</li>
</ul>
</li>
<li>保持风格一致性（一致的风格比正确的风格更重要）</li>
</ul>
<h2 id="第5章-该写什么样的注释"><a href="#第5章-该写什么样的注释" class="headerlink" title="第5章 该写什么样的注释"></a><strong>第5章 该写什么样的注释</strong></h2><ul>
<li>  注释的目的是尽量帮助读者了解的和作者一样多。</li>
<li>什么情况下不需要注释<ul>
<li>  不要为那些通过代码本身就能快速推断的信息做注释。</li>
<li>  一个好的名字比好的注释重要，不要给不好的名字加注释，应该把名字改好。</li>
<li>  好代码 &gt; 坏代码+好注释</li>
</ul>
</li>
<li>用代码记录你的思想<ul>
<li>  加入导演评论。记录自己的思考。</li>
<li>为代码中的瑕疵写注释。<ul>
<li>  增加TODO，FIXME，HACK等</li>
</ul>
</li>
</ul>
</li>
<li>站在读者的角度，去想象他们需要什么</li>
</ul>
<h2 id="第6章-写出言简意赅的注释"><a href="#第6章-写出言简意赅的注释" class="headerlink" title="第6章 写出言简意赅的注释"></a><strong>第6章 写出言简意赅的注释</strong></h2><ul>
<li>  注释应该有很高的（信息/空间）利用率</li>
<li>  让注释保持紧凑，要保持注释的简洁</li>
<li>  避免使用不明确的代词</li>
<li>  润色粗糙的句子。</li>
<li>  精确的描述函数的行为</li>
<li>  用输入、输出的示例来说明特别的情况。</li>
<li>  声明代码的意图。有时候这种注释扮演了冗余检查的角色。</li>
<li>  对于不好理解的实参，标明形参名。</li>
<li>采用信息含量高的词。<ul>
<li>  有些普遍的问题和解决方案会重复出现。通常会有专门的词或者短语代指这些场景、模式。建议采用这些值。</li>
</ul>
</li>
</ul>
<h1 id="第二部分-简化循环和逻辑"><a href="#第二部分-简化循环和逻辑" class="headerlink" title="第二部分 简化循环和逻辑"></a><strong>第二部分 简化循环和逻辑</strong></h1><ul>
<li>  控制流</li>
<li>逻辑表达式</li>
</ul>
<h2 id="第7章-把控制流变得易读"><a href="#第7章-把控制流变得易读" class="headerlink" title="第7章 把控制流变得易读"></a><strong>第7章 把控制流变得易读</strong></h2><ul>
<li>  把条件、循环以及其他对控制流的改变做的越符合直觉越好。让读者不用反复的去看一段代码。</li>
<li>条件语句中参数顺序的选择<ul>
<li>会变化的值放在比较的左侧，常量值放在比较的右侧。 <ul>
<li>  if ( length &gt; 10) 比 if ( 10 &lt;= length ) 更符合直觉</li>
<li>  while ( bytes_received &lt; bytes_excepted ) 比 while ( bytes_excepted &gt; bytes_received ) 更符合直觉。</li>
<li>  这种做法符合我们的思维习惯：“如果你的年龄不小于18岁”，“如果18岁大于等于你的年龄”。</li>
</ul>
</li>
</ul>
</li>
<li>if else 语句块的顺序，先判断哪种情况？<ul>
<li>  首先处理正逻辑的情况，如 if (debug) 而不是 if(!debug)</li>
<li>  先处理掉简单的情况。</li>
<li>  先处理特例或者复杂情况。</li>
</ul>
</li>
<li>? : 条件表达式的使用场景<ul>
<li>  如果想使用三目运算符来减少代码行数，需要判断采用三目运算符是否会导致读者理解它的成本增加。</li>
<li>  建议：默认情况都用 if else，三目运算符只在最简单的情况下使用。</li>
</ul>
</li>
<li>  在一个函数中，不同情况可以有不同的return语句</li>
<li>  不要用go/to</li>
<li>  不要用do/while</li>
<li>最小化花括号嵌套<ul>
<li>  嵌套出现的原因：对于写代码的人来说，他是从已有的条件里面找到了一个适合增加新嵌套的地方，对他来说很好理解和直观。但是对于看代码的人来说，复杂的嵌套是一个整体，思维需要频繁出入栈，不易理解。</li>
<li>  避免嵌套：每次增加嵌套都从一个全新的角度来审视，不要基于自己已有的理解。</li>
<li>  通过提前return尽快离开嵌套。</li>
</ul>
</li>
<li>减少控制流使用的次数<ul>
<li>  如线程、中断处理、异常、函数指针和匿名函数、虚方法。过多的采用会导致控制流难以理解，尽量将这些操作隔离开。</li>
</ul>
</li>
</ul>
<h2 id="第8章-拆分超长的表达式"><a href="#第8章-拆分超长的表达式" class="headerlink" title="第8章 拆分超长的表达式"></a><strong>第8章 拆分超长的表达式</strong></h2><ul>
<li>  把超长的表达式拆分成容易理解的小块。</li>
<li>  增加一个用于解释中间值的变量。</li>
<li>  容易理解的表达式，如果需要反复出现，也可以用变量代替。</li>
<li>  利用德摩根定理将判断语句等价转换，有时候可以增加可读性。</li>
<li>将短路逻辑改的直观<ul>
<li>  短路逻辑即：( if a == True || b == True ); 如果a == True为真，则 b == True不会执行 </li>
<li>  如 assert ( ( !( bucket = FindBucket(key) )) || !bucket -&gt; IsOccupied() );</li>
<li>可以改为<ul>
<li>  bucket = FindBucket(key);</li>
<li>  if (bucket != Null) assert ( !bucket -&gt; IsOccupied() );</li>
</ul>
</li>
<li>以直观为主，有时候短路逻辑反而更直观，如从a, b, c中找出第一个为真的值<ul>
<li>  x = a || b || c</li>
</ul>
</li>
</ul>
</li>
<li>反向思考，对于长判断表达式是否有更优雅的、判断它的反情况的方式。</li>
</ul>
<h2 id="第9章-变量与可读性"><a href="#第9章-变量与可读性" class="headerlink" title="第9章 变量与可读性"></a><strong>第9章 变量与可读性</strong></h2><ul>
<li>减少变量个数<ul>
<li>  减少没有价值的临时变量。</li>
<li>  减少用于保存中间结果的变量。</li>
<li>  减少用于控制流的变量。</li>
</ul>
</li>
<li>缩小变量的作用域<ul>
<li>  避免使用全局变量。 </li>
<li>  让你的变量尽量对少的代码行可见。</li>
<li>  尽量使用静态方法。</li>
<li>  把变量的定义移动到使用它之前，不要在文件开始去定义所有变量。</li>
<li>  在C++中多使用const，在Java中多使用final。这样读者就不用思考这个变量的改动。</li>
<li>  操作一个变量的地方越多，越难确定它的当前值。</li>
</ul>
</li>
</ul>
<h1 id="第三部分-重新组织代码"><a href="#第三部分-重新组织代码" class="headerlink" title="第三部分 重新组织代码"></a><strong>第三部分 重新组织代码</strong></h1><ul>
<li>  组织函数。</li>
<li>  抽取出那些与程序主要目的不相关的子问题。</li>
<li>  重新组织代码使其一次只做一件事情。</li>
<li>先用自然语言描述代码，然后用这个描述来找到更简洁的解决方案。</li>
</ul>
<h2 id="第10章-抽取不相关的子问题"><a href="#第10章-抽取不相关的子问题" class="headerlink" title="第10章 抽取不相关的子问题"></a><strong>第10章 抽取不相关的子问题</strong></h2><ul>
<li>  工程学就是把大问题拆分成小问题，再把这些小问题的解决方案放到一起。</li>
<li>  如果有一些代码在当前函数中正在解决与当前函数无关的子问题，那么就单独抽出来实现一个函数。</li>
<li>  不相关的子问题完全是自包含的，不用关心其他人怎么调用它。</li>
<li>  如果你希望有一个工具来解决现在的某个问题，那就去实现它。</li>
<li>  将代码模块化。</li>
<li>  创建大量通用式代码，自成一库。</li>
<li>  简化接口。</li>
<li>过犹不及，不要过分拆函数，以可读性为主。</li>
</ul>
<h2 id="第11章-一次只做一件事"><a href="#第11章-一次只做一件事" class="headerlink" title="第11章 一次只做一件事"></a><strong>第11章 一次只做一件事</strong></h2><ul>
<li>  将初始化对象、处理输入、逻辑等相互分开。</li>
<li>  一个代码块一次只做一件事，也可以根据需要将其拆分成不同函数。</li>
<li>任务可以分的很细。</li>
</ul>
<h2 id="第12章-把想法变成代码"><a href="#第12章-把想法变成代码" class="headerlink" title="第12章 把想法变成代码"></a><strong>第12章 把想法变成代码</strong></h2><ul>
<li>  如果你不能让一个完全没有基础的人把你所做的事情听明白，那么你就没有真正理解这件事。</li>
<li>代码就是你想法的实现，读者需要从你的实现中理解你的代码<ul>
<li>  像对着同事一样用自然语言描述代码要做什么。</li>
<li>  注意描述中所用的关键词和短语。</li>
<li>  写出与描述相匹配的代码。</li>
</ul>
</li>
<li>  清楚地描述逻辑。</li>
<li>了解你所用的函数库。</li>
</ul>
<h2 id="第13章-少写代码"><a href="#第13章-少写代码" class="headerlink" title="第13章 少写代码"></a><strong>第13章 少写代码</strong></h2><ul>
<li>  最好读的代码就是没有代码。</li>
<li>  功能越简洁越好。</li>
<li>质疑和拆分你的需求，它真的需要这个功能吗？<ul>
<li>  减少需求。</li>
<li>  解决更简单的问题。</li>
</ul>
</li>
<li>代码库越小、越轻量越好。<ul>
<li>  创建越多越好的工具代码来减少重复代码。</li>
<li>  减少无用代码或者无用功能。</li>
<li>  让项目保持独立的子项目状态。</li>
</ul>
</li>
<li>熟悉你所使用的库，很多你需要的功能它们已经实现了。<ul>
<li>  每隔一段时间，花15分钟阅读标准库中的所有函数、模块、类型名。并不是为了记住，而是需要的时候有个印象，知道无需自己实现。</li>
</ul>
</li>
<li>  代码越多就越难维护。</li>
<li>不要过度设计。</li>
</ul>
<h1 id="第四部分-精选话题"><a href="#第四部分-精选话题" class="headerlink" title="第四部分 精选话题"></a><strong>第四部分 精选话题</strong></h1><ul>
<li>作者精选出的两个应用示例。</li>
</ul>
<h2 id="第14章-测试与可读性"><a href="#第14章-测试与可读性" class="headerlink" title="第14章 测试与可读性"></a><strong>第14章 测试与可读性</strong></h2><ul>
<li>  对使用者隐去不重要的细节，以便更重要的细节更加突出。</li>
<li>  让打印信息具有可读性。</li>
<li>了解常用的一些库。如python中的unittest。</li>
</ul>
<h2 id="第15章-设计并改进“分钟-小时计数器”"><a href="#第15章-设计并改进“分钟-小时计数器”" class="headerlink" title="第15章 设计并改进“分钟/小时计数器”"></a><strong>第15章 设计并改进“分钟/小时计数器”</strong></h2><ul>
<li>  一个更加具体的案例。</li>
</ul>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>coding</tag>
      </tags>
  </entry>
</search>
